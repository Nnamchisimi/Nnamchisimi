{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOI7HVv6lOhA2eBd89YdK1B",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nnamchisimi/Nnamchisimi/blob/main/(use)Backorder_and_updated_stckdateetc.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "updated, for bckorder and rejected , empty stckentrydate(12/05/2024)"
      ],
      "metadata": {
        "id": "z83TPrUFRgUv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "wl3WHFKYQsKd",
        "outputId": "e50c459c-a08a-497e-cf63-c54d493632d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the customer info: girne\n",
            "Customer info Details:\n",
            "       ±     gATP  Code Cust. No.  Cust. order no.              Part number  \\\n",
            "127   ⊞    Green   C21   CY822025         42871473  A 222 905 5111     9051   \n",
            "128   ⊞    Green   C21   CY822025         42871473  A 222 905 0309     9051   \n",
            "129   ⊞    Green   C21   CY822025         42871473  A 213 905 4803     9051   \n",
            "617   ⊞   Yellow   C22   CY822025         42621444           A 222 899 0600   \n",
            "618   ⊞    Green         CY822025         42621444           A 270 200 0200   \n",
            "619   ⊞    Green         CY822025         42621444           A 205 330 5801   \n",
            "620   ⊞    Green         CY822025         42621444           A 002 990 2017   \n",
            "621   ⊞    Green         CY822025         42621444           A 210 501 0615   \n",
            "622   ⊞    Green         CY822025         42621444           A 654 094 0204   \n",
            "624   ⊞    Green         CY822025         42621444           A 169 540 1617   \n",
            "635   ⊞   Yellow   C22   CY822025         42621444           A 222 899 0600   \n",
            "636   ⊞    Green         CY822025         42621444           A 024 997 1045   \n",
            "637   ⊞    Green         CY822025         42621444       A 000 997 3807  64   \n",
            "639   ⊞    Green         CY822025         42621444           A 177 820 9900   \n",
            "906   ⊞    Green         CY822025         42521426           A 205 501 7601   \n",
            "907   ⊞    Green         CY822025         42521426           A 205 501 1001   \n",
            "908   ⊞    Green         CY822025         42521426           A 205 501 1001   \n",
            "1367  ⊞    Green         CY822025         42361406           A 223 421 4200   \n",
            "1368  ⊞    Green         CY822025         42361406           A 223 824 0100   \n",
            "1370  ⊞    Green   C21   CY822025         42361406       A 000 905 8011  80   \n",
            "1874  ⊞   Yellow         CY822025         42271358           A 000 828 0388   \n",
            "1917  ⊞    Green         CY822025         42271358           A 231 905 0014   \n",
            "1918  ⊞    Green         CY822025         42271358           A 447 420 6600   \n",
            "1919  ⊞    Green         CY822025         42271358           A 447 420 6700   \n",
            "2395  ⊞   Yellow         CY822025         42201347           A 223 421 4200   \n",
            "3277  ⊞   Yellow         CY822025         42031303           A 222 899 0600   \n",
            "3280  ⊞    Green         CY822025         42031303           A 006 997 1890   \n",
            "3281  ⊞    Green         CY822025         42031303           A 169 540 1617   \n",
            "3282  ⊞    Green         CY822025         42031303           A 274 070 3500   \n",
            "3284  ⊞    Green         CY822025         42031303           A 270 159 0600   \n",
            "3286  ⊞    Green         CY822025         42031303           A 222 330 0107   \n",
            "3287  ⊞    Green         CY822025         42031303           A 222 330 0207   \n",
            "\n",
            "     Designation of part no. Ordered Designation of part no. Confirmed  \\\n",
            "127                     SWITCH BLOCK                      SWITCH BLOCK   \n",
            "128                     SWITCH BLOCK                      SWITCH BLOCK   \n",
            "129                     SWITCH BLOCK                      SWITCH BLOCK   \n",
            "617                           FLACON                            FLACON   \n",
            "618         COOLANT INLET CONNECTION          COOLANT INLET CONNECTION   \n",
            "619                      SPRING LINK                       SPRING LINK   \n",
            "620                       SCREW PLUG                        SCREW PLUG   \n",
            "621                      CLOSING CAP                       CLOSING CAP   \n",
            "622               AIR FILTER ELEMENT                AIR FILTER ELEMENT   \n",
            "624             BRAKEPAD WEAR SENSOR              BRAKEPAD WEAR SENSOR   \n",
            "635                           FLACON                            FLACON   \n",
            "636                           O-RING                            O-RING   \n",
            "637                           O-RING                            O-RING   \n",
            "639           PARTS KIT, WIPER BLADE            PARTS KIT, WIPER BLADE   \n",
            "906                       BLEED LINE                        BLEED LINE   \n",
            "907                       BLEED LINE                        BLEED LINE   \n",
            "908                       BLEED LINE                        BLEED LINE   \n",
            "1367              BRAKE DISK, VENTED                BRAKE DISK, VENTED   \n",
            "1368          PARTS KIT, WIPER BLADE            PARTS KIT, WIPER BLADE   \n",
            "1370                      NOX SENSOR                        NOX SENSOR   \n",
            "1874                    BATTERY PACK                      BATTERY PACK   \n",
            "1917            BRAKEPAD WEAR SENSOR              BRAKEPAD WEAR SENSOR   \n",
            "1918             PARTS KIT, BRAKEPAD               PARTS KIT, BRAKEPAD   \n",
            "1919             PARTS KIT, BRAKEPAD               PARTS KIT, BRAKEPAD   \n",
            "2395              BRAKE DISK, VENTED                BRAKE DISK, VENTED   \n",
            "3277                          FLACON                            FLACON   \n",
            "3280                      HOSE CLAMP                        HOSE CLAMP   \n",
            "3281            BRAKEPAD WEAR SENSOR              BRAKEPAD WEAR SENSOR   \n",
            "3282                       FUEL HOSE                         FUEL HOSE   \n",
            "3284                      SPARK PLUG                        SPARK PLUG   \n",
            "3286                     SPRING LINK                       SPRING LINK   \n",
            "3287                     SPRING LINK                       SPRING LINK   \n",
            "\n",
            "                Ord. date Items status  ...  M code Shelf life  \\\n",
            "127   13/08/2024 12:48 pm    Completed  ...  1PV546        NaN   \n",
            "128   13/08/2024 12:48 pm    Completed  ...  1PV546        NaN   \n",
            "129   13/08/2024 12:48 pm    Completed  ...  1PV543        NaN   \n",
            "617   25/07/2024 05:51 pm    Completed  ...  1PZ733        NaN   \n",
            "618   25/07/2024 05:51 pm    Completed  ...  1PV141        NaN   \n",
            "619   25/07/2024 05:51 pm    Completed  ...  1PV032        NaN   \n",
            "620   25/07/2024 05:51 pm    Completed  ...  1PV980        NaN   \n",
            "621   25/07/2024 05:51 pm    Completed  ...  1PV176        NaN   \n",
            "622   25/07/2024 05:51 pm    Completed  ...  1PW130        NaN   \n",
            "624   25/07/2024 05:51 pm    Completed  ...  1PV413        NaN   \n",
            "635   25/07/2024 05:51 pm    Completed  ...  1PZ733        NaN   \n",
            "636   25/07/2024 05:51 pm    Completed  ...  1PV986        NaN   \n",
            "637   25/07/2024 05:51 pm    Completed  ...  1PV986        NaN   \n",
            "639   25/07/2024 05:51 pm    Completed  ...  1PV565        NaN   \n",
            "906   11/07/2024 01:03 pm    Completed  ...  1PV517        NaN   \n",
            "907   11/07/2024 01:03 pm    Completed  ...  1PV517        NaN   \n",
            "908   11/07/2024 01:03 pm    Completed  ...  1PV517        NaN   \n",
            "1367  15/06/2024 04:13 pm    Completed  ...  1PV425        NaN   \n",
            "1368  15/06/2024 04:13 pm    Completed  ...  1PV565        NaN   \n",
            "1370  15/06/2024 04:13 pm    Completed  ...  1PE547        NaN   \n",
            "1874  29/05/2024 11:00 am    Completed  ...  1OX000      120.0   \n",
            "1917  23/05/2024 11:21 am    Completed  ...  1PV413        NaN   \n",
            "1918  23/05/2024 11:21 am    Completed  ...  2TV415        NaN   \n",
            "1919  23/05/2024 11:21 am    Completed  ...  2TV415        NaN   \n",
            "2395  13/05/2024 06:22 pm    Completed  ...  1PV425        NaN   \n",
            "3277  09/04/2024 02:41 pm    Completed  ...  1PZ733        NaN   \n",
            "3280  09/04/2024 02:41 pm    Completed  ...  1PV981        NaN   \n",
            "3281  09/04/2024 02:41 pm    Completed  ...  1PV413        NaN   \n",
            "3282  09/04/2024 02:41 pm    Completed  ...  1PV637        NaN   \n",
            "3284  09/04/2024 02:41 pm    Completed  ...  1PV580        NaN   \n",
            "3286  09/04/2024 02:41 pm    Completed  ...  1PV032        NaN   \n",
            "3287  09/04/2024 02:41 pm    Completed  ...  1PV032        NaN   \n",
            "\n",
            "     Return excluded DRT ID Request no. Hub ind. CON Costing code  \\\n",
            "127                     NaN         NaN       X  NaN          NaN   \n",
            "128                     NaN         NaN       X  NaN          NaN   \n",
            "129                     NaN         NaN       X  NaN          NaN   \n",
            "617               X     NaN         NaN       X  NaN          NaN   \n",
            "618                     NaN         NaN       X  NaN          NaN   \n",
            "619                     NaN         NaN       X  NaN          NaN   \n",
            "620                     NaN         NaN       X  NaN          NaN   \n",
            "621                     NaN         NaN       X  NaN          NaN   \n",
            "622                     NaN         NaN       X  NaN          NaN   \n",
            "624                     NaN         NaN       X  NaN          NaN   \n",
            "635               X     NaN         NaN       X  NaN          NaN   \n",
            "636                     NaN         NaN       X  NaN          NaN   \n",
            "637                     NaN         NaN       X  NaN          NaN   \n",
            "639                     NaN         NaN       X  NaN          NaN   \n",
            "906                     NaN         NaN       X  NaN          NaN   \n",
            "907                     NaN         NaN       X  NaN          NaN   \n",
            "908                     NaN         NaN       X  NaN          NaN   \n",
            "1367                    NaN         NaN       X  NaN          NaN   \n",
            "1368                    NaN         NaN       X  NaN          NaN   \n",
            "1370              X     NaN         NaN       X  NaN          NaN   \n",
            "1874              X     NaN         NaN          NaN          NaN   \n",
            "1917                    NaN         NaN       X  NaN          NaN   \n",
            "1918                    NaN         NaN       X  NaN          NaN   \n",
            "1919                    NaN         NaN       X  NaN          NaN   \n",
            "2395                    NaN         NaN       X  NaN          NaN   \n",
            "3277              X     NaN         NaN       X  NaN          NaN   \n",
            "3280                    NaN         NaN       X  NaN          NaN   \n",
            "3281                    NaN         NaN       X  NaN          NaN   \n",
            "3282                    NaN         NaN       X  NaN          NaN   \n",
            "3284                    NaN         NaN       X  NaN          NaN   \n",
            "3286                    NaN         NaN       X  NaN          NaN   \n",
            "3287                    NaN         NaN       X  NaN          NaN   \n",
            "\n",
            "     Situation report Cleaned Customer info  \n",
            "127               NaN                 GIRNE  \n",
            "128               NaN                 GIRNE  \n",
            "129               NaN                 GIRNE  \n",
            "617               NaN                 GIRNE  \n",
            "618               NaN                 GIRNE  \n",
            "619               NaN                 GIRNE  \n",
            "620               NaN                 GIRNE  \n",
            "621               NaN                 GIRNE  \n",
            "622               NaN                 GIRNE  \n",
            "624               NaN                 GIRNE  \n",
            "635               NaN                 GIRNE  \n",
            "636               NaN                 GIRNE  \n",
            "637               NaN                 GIRNE  \n",
            "639               NaN                 GIRNE  \n",
            "906               NaN                 GIRNE  \n",
            "907               NaN                 GIRNE  \n",
            "908               NaN                 GIRNE  \n",
            "1367              NaN                 GIRNE  \n",
            "1368              NaN                 GIRNE  \n",
            "1370              NaN                 GIRNE  \n",
            "1874              NaN                 GIRNE  \n",
            "1917              NaN                 GIRNE  \n",
            "1918              NaN                 GIRNE  \n",
            "1919              NaN                 GIRNE  \n",
            "2395              NaN                 GIRNE  \n",
            "3277              NaN                 GIRNE  \n",
            "3280              NaN                 GIRNE  \n",
            "3281              NaN                 GIRNE  \n",
            "3282              NaN                 GIRNE  \n",
            "3284              NaN                 GIRNE  \n",
            "3286              NaN                 GIRNE  \n",
            "3287              NaN                 GIRNE  \n",
            "\n",
            "[32 rows x 63 columns]\n",
            "Merged data has been saved to /content/cgniv_StarOrderplus_Order_items.xlsx\n",
            "Number of rows in the original df2 file: 2124\n",
            "Number of rows in the result file: 2124\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-f2ba71e89122>\u001b[0m in \u001b[0;36m<cell line: 214>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;31m# Search for tracking numbers in emails\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m \u001b[0mtracking_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msearch_emails_for_tracking_numbers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdn_numbers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[0;31m# Update the existing entries with the tracking numbers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-f2ba71e89122>\u001b[0m in \u001b[0;36msearch_emails_for_tracking_numbers\u001b[0;34m(dn_numbers)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0memail_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0memail_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0memail_ids\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m         \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmail\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memail_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'(RFC822)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'OK'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Failed to fetch email with ID {email_id}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/imaplib.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, message_set, message_parts)\u001b[0m\n\u001b[1;32m    546\u001b[0m         \"\"\"\n\u001b[1;32m    547\u001b[0m         \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'FETCH'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 548\u001b[0;31m         \u001b[0mtyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_simple_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage_parts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    549\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_untagged_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/imaplib.py\u001b[0m in \u001b[0;36m_simple_command\u001b[0;34m(self, name, *args)\u001b[0m\n\u001b[1;32m   1228\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_simple_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1230\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_command_complete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/imaplib.py\u001b[0m in \u001b[0;36m_command_complete\u001b[0;34m(self, name, tag)\u001b[0m\n\u001b[1;32m   1045\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_bye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1047\u001b[0;31m             \u001b[0mtyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tagged_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_bye\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1048\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabort\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1049\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'command: %s => %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/imaplib.py\u001b[0m in \u001b[0;36m_get_tagged_response\u001b[0;34m(self, tag, expect_bye)\u001b[0m\n\u001b[1;32m   1171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1173\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1174\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabort\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0m__debug__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/imaplib.py\u001b[0m in \u001b[0;36m_get_response\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1073\u001b[0m         \u001b[0;31m# otherwise first response line received.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1074\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1075\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1076\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1077\u001b[0m         \u001b[0;31m# Command completion response?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/imaplib.py\u001b[0m in \u001b[0;36m_get_line\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1181\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'socket error: EOF'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/imaplib.py\u001b[0m in \u001b[0;36mreadline\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m         \u001b[0;34m\"\"\"Read line from remote.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"got more than %d bytes\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 705\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    706\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1301\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1302\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1303\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1304\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1305\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1157\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1158\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1159\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1160\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1161\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from datetime import timedelta\n",
        "import imaplib\n",
        "import email\n",
        "from email.header import decode_header\n",
        "import chardet\n",
        "import re\n",
        "\n",
        "# Email account credentials\n",
        "username = 'kombosawb@gmail.com'\n",
        "password = 'kyka ypey hfar rjvg'  # Use the App Password here\n",
        "\n",
        "# File paths for input Excel files\n",
        "file_path = '/content/updated_Order_items (2).xlsx'\n",
        "file_path1 = '/content/updated_Mercedes_Yedek_Parça_Sipariş_2024 (2).xlsx'\n",
        "file_path2 = '/content/niv_StarOrderplus_Order_items_new.xlsx'\n",
        "input_file = '/content/cgniv_StarOrderplus_Order_items.xlsx'\n",
        "\n",
        "# File path for the output Excel file\n",
        "output_file = '/content/vaugzcstcketrd_expstckentryd_status_trcklnk_trckno.xlsx'\n",
        "\n",
        "# Load and clean the first Excel file\n",
        "df = pd.read_excel(file_path)\n",
        "\n",
        "# Create 'Cleaned Customer info' column by removing spaces and unwanted characters\n",
        "if 'Customer info' in df.columns:\n",
        "    df['Cleaned Customer info'] = df['Customer info'].astype(str).str.replace(' ', '').str.upper().str.replace(r'[^A-Za-z0-9]', '', regex=True)\n",
        "else:\n",
        "    print(\"The column 'Customer info' was not found in the file.\")\n",
        "    df['Cleaned Customer info'] = df['Customer info']\n",
        "\n",
        "# Remove rows with unwanted 'Customer info' entries\n",
        "df_cleaned = df[~df['Cleaned Customer info'].str.lower().str.startswith(('stok', 'stpk', 'minarelikoy', 'mýna', 'stock', 'raf')) &\n",
        "                ~df['Cleaned Customer info'].str.startswith(('RAF', 'STOCKMT'))]\n",
        "\n",
        "# Save the cleaned DataFrame to a new Excel file\n",
        "df_cleaned.to_excel(file_path2, index=False)\n",
        "\n",
        "# Function to get customer info details\n",
        "def get_customer_info_details():\n",
        "    customer_info_input = input(\"Enter the customer info: \").strip()\n",
        "    if 'Cleaned Customer info' in df_cleaned.columns:\n",
        "        part_details = df_cleaned[df_cleaned['Cleaned Customer info'].astype(str).str.contains(customer_info_input, case=False, na=False)]\n",
        "    else:\n",
        "        print(\"The column 'Cleaned Customer info' was not found in the cleaned file.\")\n",
        "        return\n",
        "\n",
        "    if not part_details.empty:\n",
        "        print(\"Customer info Details:\")\n",
        "        print(part_details)\n",
        "    else:\n",
        "        print(\"No details found for the entered customer info.\")\n",
        "\n",
        "# Run the function\n",
        "get_customer_info_details()\n",
        "\n",
        "# Load the cleaned DataFrame and other Excel files\n",
        "df_cleaned = pd.read_excel(file_path2)\n",
        "df1 = pd.read_excel(file_path1)\n",
        "df2 = pd.read_excel(file_path2)\n",
        "\n",
        "# Check for required columns in df1 and df2\n",
        "required_columns = {'Customer info', 'Part number'}\n",
        "missing_columns_df1 = required_columns - set(df1.columns)\n",
        "missing_columns_df2 = required_columns - set(df2.columns)\n",
        "\n",
        "if missing_columns_df1:\n",
        "    print(f\"The following required columns are missing in the first file: {missing_columns_df1}\")\n",
        "if missing_columns_df2:\n",
        "    print(f\"The following required columns are missing in the second file: {missing_columns_df2}\")\n",
        "\n",
        "if not missing_columns_df1 and not missing_columns_df2:\n",
        "    # Clean 'Part number' columns in df1 and df2\n",
        "    df1['Cleaned Part number'] = df1['Part number'].astype(str).str.replace(' ', '').str.upper().str[:10]\n",
        "    df2['Cleaned Part number'] = df2['Part number'].astype(str).str.replace(' ', '').str.upper().str[:10]\n",
        "\n",
        "    # Clean 'Customer info' columns in df1\n",
        "    df1['Cleaned Customer info'] = df1['Customer info'].astype(str).str.replace(' ', '').str.upper().str.replace(r'[^A-Za-z0-9]', '', regex=True)\n",
        "    df1_unique = df1.drop_duplicates(subset=['Cleaned Customer info', 'Cleaned Part number'])\n",
        "\n",
        "    # Clean 'Customer info' columns in df2\n",
        "    df2['Cleaned Customer info'] = df2['Customer info'].astype(str).str.replace(' ', '').str.upper().str.replace(r'[^A-Za-z0-9]', '', regex=True)\n",
        "\n",
        "    # Merge 'StockEntryDate' from df1_unique into df2 based on cleaned columns\n",
        "    merged_df = pd.merge(df2, df1_unique[['Cleaned Customer info', 'Cleaned Part number', 'StockEntryDate']],\n",
        "                         on=['Cleaned Customer info', 'Cleaned Part number'], how='left')\n",
        "\n",
        "    # Save the resulting DataFrame\n",
        "    merged_df.to_excel(input_file, index=False)\n",
        "    print(f\"Merged data has been saved to {input_file}\")\n",
        "    print(f\"Number of rows in the original df2 file: {len(df2)}\")\n",
        "    print(f\"Number of rows in the result file: {len(merged_df)}\")\n",
        "\n",
        "else:\n",
        "    print(\"One or both required columns 'Customer info' or 'Part number' were not found in the provided files.\")\n",
        "\n",
        "# Load the updated DataFrame\n",
        "df = pd.read_excel(input_file)\n",
        "\n",
        "# Connect to the email server\n",
        "mail = imaplib.IMAP4_SSL('imap.gmail.com')\n",
        "\n",
        "def fetch_stt_number(body):\n",
        "    stt_number_match = re.search(r'STT Number[:\\.\\s]+(\\d+)', body)\n",
        "    return stt_number_match.group(1) if stt_number_match else 'Not Found'\n",
        "\n",
        "def search_emails_for_tracking_numbers(dn_numbers):\n",
        "    tracking_dict = {dn_number: 'Not Found' for dn_number in dn_numbers}\n",
        "    mail.login(username, password)\n",
        "    mail.select('inbox')\n",
        "\n",
        "    result, data = mail.search(None, 'ALL')\n",
        "    if result != 'OK':\n",
        "        print(\"Failed to search for emails.\")\n",
        "        return tracking_dict\n",
        "\n",
        "    email_ids = data[0].split()\n",
        "    for email_id in email_ids:\n",
        "        result, msg_data = mail.fetch(email_id, '(RFC822)')\n",
        "        if result != 'OK':\n",
        "            print(f\"Failed to fetch email with ID {email_id}\")\n",
        "            continue\n",
        "\n",
        "        raw_email = msg_data[0][1]\n",
        "        msg = email.message_from_bytes(raw_email)\n",
        "\n",
        "        # Decode email body\n",
        "        body = \"\"\n",
        "        if msg.is_multipart():\n",
        "            for part in msg.walk():\n",
        "                if part.get_content_type() == 'text/plain':\n",
        "                    payload = part.get_payload(decode=True)\n",
        "                    detected_encoding = chardet.detect(payload)['encoding']\n",
        "                    body = payload.decode(detected_encoding or 'utf-8', errors='replace')\n",
        "                    break\n",
        "        else:\n",
        "            payload = msg.get_payload(decode=True)\n",
        "            detected_encoding = chardet.detect(payload)['encoding']\n",
        "            body = payload.decode(detected_encoding or 'utf-8', errors='replace')\n",
        "\n",
        "        # Check for each DN number in the body\n",
        "        for dn_number in dn_numbers:\n",
        "            if dn_number in body:\n",
        "                tracking_dict[dn_number] = fetch_stt_number(body)\n",
        "\n",
        "    return tracking_dict\n",
        "\n",
        "# Define the function to compute the expected stock entry date\n",
        "def calculate_expected_stock_entry_date(row):\n",
        "    try:\n",
        "        inv_date_dispatch_date = pd.to_datetime(row['Inv. date dispatch date'], dayfirst=True, errors='coerce')\n",
        "        if pd.notnull(inv_date_dispatch_date):\n",
        "            conf_dd_confirmed_dispatch_date = pd.to_datetime(row['Conf. DD confirmed dispatch date'], dayfirst=True, errors='coerce')\n",
        "            expected_dd_expected_to_be_dispatched = pd.to_datetime(row['Expected DD expecte to be dispatched'], dayfirst=True, errors='coerce')\n",
        "\n",
        "            if row['Dist. ch.'] == 'af VOR direct':\n",
        "                days_to_add = 10\n",
        "            elif row['Dist. ch.'] == 'VOR route':\n",
        "                days_to_add = 21\n",
        "            else:\n",
        "                days_to_add = 10\n",
        "\n",
        "            return inv_date_dispatch_date + timedelta(days=days_to_add)\n",
        "        return pd.NaT\n",
        "    except KeyError as e:\n",
        "        print(f\"Column not found: {e}\")\n",
        "        return pd.NaT\n",
        "\n",
        "# Apply the function to each row to create the new column\n",
        "df['expectedstockentrydate'] = df.apply(calculate_expected_stock_entry_date, axis=1)\n",
        "\n",
        "# Define the function to compute the status\n",
        "def determine_status(row):\n",
        "    inv_date_dispatch_date = pd.to_datetime(row.get('Inv. date dispatch date', None), dayfirst=True, errors='coerce')\n",
        "    conf_dd_confirmed_dispatch_date = pd.to_datetime(row.get('Conf. DD confirmed dispatch date', None), dayfirst=True, errors='coerce')\n",
        "    expected_dd_expected_to_be_dispatched = pd.to_datetime(row.get('Expected DD expecte to be dispatched', None), dayfirst=True, errors='coerce')\n",
        "\n",
        "    if pd.notnull(inv_date_dispatch_date):\n",
        "        return f'invoice dispatch date on {inv_date_dispatch_date.strftime(\"%d/%m/%Y\")}'\n",
        "    elif pd.notnull(conf_dd_confirmed_dispatch_date):\n",
        "        return f'confirmed dispatch date on {conf_dd_confirmed_dispatch_date.strftime(\"%d/%m/%Y\")}'\n",
        "    elif pd.notnull(expected_dd_expected_to_be_dispatched):\n",
        "        return 'backorder'\n",
        "    else:\n",
        "        return 'backorder'\n",
        "\n",
        "# Apply the function to create the new status column\n",
        "df['status'] = df.apply(determine_status, axis=1)\n",
        "\n",
        "# Update status for rejected items\n",
        "df.loc[(df['Items status'] == 'Rejected') & (df['status'] == 'backorder'), 'status'] = 'Rejected'\n",
        "\n",
        "# Create the list_of_backorders column for searching\n",
        "def determine_backorders(row):\n",
        "    inv_date_dispatch_date = pd.to_datetime(row.get('Inv. date dispatch date', None), dayfirst=True, errors='coerce')\n",
        "    conf_dd_confirmed_dispatch_date = pd.to_datetime(row.get('Conf. DD confirmed dispatch date', None), dayfirst=True, errors='coerce')\n",
        "    expected_dd_expected_to_be_dispatched = pd.to_datetime(row.get('Expected DD expecte to be dispatched', None), dayfirst=True, errors='coerce')\n",
        "\n",
        "    if pd.isnull(inv_date_dispatch_date) and pd.isnull(conf_dd_confirmed_dispatch_date) and (pd.notnull(expected_dd_expected_to_be_dispatched) or pd.isnull(expected_dd_expected_to_be_dispatched)):\n",
        "        return 'backorders'\n",
        "    else:\n",
        "        return ''\n",
        "\n",
        "# Apply the function to create the new list_of_backorders column\n",
        "df['list_of_backorders'] = df.apply(determine_backorders, axis=1)\n",
        "\n",
        "# Filter out 'Rejected' items when searching for backorders\n",
        "filtered_df = df[(df['status'] == 'backorder') & (df['list_of_backorders'] == 'backorders')]\n",
        "\n",
        "# Get the list of DN numbers from the DataFrame\n",
        "dn_numbers = df['DN no.'].dropna().astype(str).tolist()\n",
        "\n",
        "# Search for tracking numbers in emails\n",
        "tracking_dict = search_emails_for_tracking_numbers(dn_numbers)\n",
        "\n",
        "# Update the existing entries with the tracking numbers\n",
        "df['Tracking No'] = df['DN no.'].map(tracking_dict)\n",
        "\n",
        "# Create the tracking details column\n",
        "df['tracking_details'] = df['Tracking No'].apply(lambda x: f'https://dbschenker.com/app/tracking-public/?refNumber={x}' if x != 'Not Found' else '')\n",
        "\n",
        "# Set tracking_details to blank if the value contains 'nan'\n",
        "df['tracking_details'] = df['tracking_details'].apply(lambda x: '' if 'nan' in x else x)\n",
        "\n",
        "# Set StockEntryDate to NaT where status is 'backorder' or 'Rejected'\n",
        "df.loc[df['status'].isin(['backorder', 'Rejected']), 'StockEntryDate'] = pd.NaT\n",
        "\n",
        "# Save results to a new Excel file\n",
        "df.to_excel(output_file, index=False)\n",
        "print(f\"Updated file saved to {output_file}\")\n",
        "\n",
        "# Close the connection and logout\n",
        "mail.close()\n",
        "mail.logout()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "does not recognize tags behind customer info (fixed) 13/08/2024"
      ],
      "metadata": {
        "id": "471okUe3YHf5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from datetime import timedelta\n",
        "import imaplib\n",
        "import email\n",
        "from email.header import decode_header\n",
        "import chardet\n",
        "import re\n",
        "\n",
        "# Email account credentials\n",
        "username = 'kombosawb@gmail.com'\n",
        "password = 'kyka ypey hfar rjvg'  # Use the App Password here\n",
        "\n",
        "# File paths for input Excel files\n",
        "file_path = '/content/updated_Order_items (11).xlsx'\n",
        "file_path1 = '/content/updated_Mercedes_Yedek_Parça_Sipariş_2024 (11).xlsx'\n",
        "file_path2 = '/content/niv_StarOrderplus_Order_items_new.xlsx'\n",
        "input_file = '/content/cgniv_StarOrderplus_Order_items.xlsx'\n",
        "\n",
        "# File path for the output Excel file\n",
        "output_file = '/content/vaugzcstcketrd_expstckentryd_status_trcklnk_trckno.xlsx'\n",
        "exdf1= '/content/df1_unique.xlsx'\n",
        "exdf2= '/content/df2.xlsx'\n",
        "df1.to_excel(exdf1, index=False)\n",
        "df2.to_excel(exdf2, index=False)\n",
        "# Load and clean the first Excel file\n",
        "df = pd.read_excel(file_path)\n",
        "\n",
        "# Create 'Cleaned Customer info' column by removing spaces, unwanted characters, and suffixes like '-mt'\n",
        "if 'Customer info' in df.columns:\n",
        "    df['Cleaned Customer info'] = df['Customer info'].astype(str).str.replace(' ', '').str.upper().str.replace(r'-[A-Z]+$', '', regex=True)\n",
        "else:\n",
        "    print(\"The column 'Customer info' was not found in the file.\")\n",
        "    df['Cleaned Customer info'] = df['Customer info']\n",
        "\n",
        "# Remove rows with unwanted 'Customer info' entries\n",
        "df_cleaned = df[~df['Cleaned Customer info'].str.lower().str.startswith(('stok', 'stpk', 'minarelikoy', 'mýna', 'stock', 'raf')) &\n",
        "                ~df['Cleaned Customer info'].str.startswith(('RAF', 'STOCKMT'))]\n",
        "\n",
        "# Save the cleaned DataFrame to a new Excel file\n",
        "df_cleaned.to_excel(file_path2, index=False)\n",
        "\n",
        "# Function to get customer info details\n",
        "def get_customer_info_details():\n",
        "    customer_info_input = input(\"Enter the customer info: \").strip()\n",
        "    if 'Cleaned Customer info' in df_cleaned.columns:\n",
        "        part_details = df_cleaned[df_cleaned['Cleaned Customer info'].astype(str).str.contains(customer_info_input, case=False, na=False)]\n",
        "    else:\n",
        "        print(\"The column 'Cleaned Customer info' was not found in the cleaned file.\")\n",
        "        return\n",
        "\n",
        "    if not part_details.empty:\n",
        "        print(\"Customer info Details:\")\n",
        "        print(part_details)\n",
        "    else:\n",
        "        print(\"No details found for the entered customer info.\")\n",
        "\n",
        "# Run the function\n",
        "get_customer_info_details()\n",
        "\n",
        "# Load the cleaned DataFrame and other Excel files\n",
        "df_cleaned = pd.read_excel(file_path2)\n",
        "df1 = pd.read_excel(file_path1)\n",
        "df2 = pd.read_excel(file_path2)\n",
        "\n",
        "# Check for required columns in df1 and df2\n",
        "required_columns = {'Customer info', 'Part number'}\n",
        "missing_columns_df1 = required_columns - set(df1.columns)\n",
        "missing_columns_df2 = required_columns - set(df2.columns)\n",
        "\n",
        "if missing_columns_df1:\n",
        "    print(f\"The following required columns are missing in the first file: {missing_columns_df1}\")\n",
        "if missing_columns_df2:\n",
        "    print(f\"The following required columns are missing in the second file: {missing_columns_df2}\")\n",
        "\n",
        "if not missing_columns_df1 and not missing_columns_df2:\n",
        "    # Clean 'Part number' columns in df1 and df2\n",
        "    df1['Cleaned Part number'] = df1['Part number'].astype(str).str.replace(' ', '').str.upper().str[:10]\n",
        "    df2['Cleaned Part number'] = df2['Part number'].astype(str).str.replace(' ', '').str.upper().str[:10]\n",
        "\n",
        "    # Clean 'Customer info' columns in df1\n",
        "    df1['Cleaned Customer info'] = df1['Customer info'].astype(str).str.replace(' ', '').str.upper().str.replace(r'-[A-Z]+$', '', regex=True)\n",
        "    df1_unique = df1.drop_duplicates(subset=['Cleaned Customer info', 'Cleaned Part number'])\n",
        "\n",
        "    # Clean 'Customer info' columns in df2\n",
        "    df2['Cleaned Customer info'] = df2['Customer info'].astype(str).str.replace(' ', '').str.upper().str.replace(r'-[A-Z]+$', '', regex=True)\n",
        "\n",
        "    # Merge 'StockEntryDate' from df1_unique into df2 based on cleaned columns\n",
        "    merged_df = pd.merge(df2, df1_unique[['Cleaned Customer info', 'Cleaned Part number', 'StockEntryDate']],\n",
        "                         on=['Cleaned Customer info', 'Cleaned Part number'], how='left')\n",
        "\n",
        "    # Save the resulting DataFrame\n",
        "    merged_df.to_excel(input_file, index=False)\n",
        "    print(f\"Merged data has been saved to {input_file}\")\n",
        "    print(f\"Number of rows in the original df2 file: {len(df2)}\")\n",
        "    print(f\"Number of rows in the result file: {len(merged_df)}\")\n",
        "\n",
        "else:\n",
        "    print(\"One or both required columns 'Customer info' or 'Part number' were not found in the provided files.\")\n",
        "\n",
        "# Load the updated DataFrame\n",
        "df = pd.read_excel(input_file)\n",
        "\n",
        "# Connect to the email server\n",
        "mail = imaplib.IMAP4_SSL('imap.gmail.com')\n",
        "\n",
        "def fetch_stt_number(body):\n",
        "    stt_number_match = re.search(r'STT Number[:\\.\\s]+(\\d+)', body)\n",
        "    return stt_number_match.group(1) if stt_number_match else 'Not Found'\n",
        "\n",
        "def search_emails_for_tracking_numbers(dn_numbers):\n",
        "    tracking_dict = {dn_number: 'Not Found' for dn_number in dn_numbers}\n",
        "    mail.login(username, password)\n",
        "    mail.select('inbox')\n",
        "\n",
        "    result, data = mail.search(None, 'ALL')\n",
        "    if result != 'OK':\n",
        "        print(\"Failed to search for emails.\")\n",
        "        return tracking_dict\n",
        "\n",
        "    email_ids = data[0].split()\n",
        "    for email_id in email_ids:\n",
        "        result, msg_data = mail.fetch(email_id, '(RFC822)')\n",
        "        if result != 'OK':\n",
        "            print(f\"Failed to fetch email with ID {email_id}\")\n",
        "            continue\n",
        "\n",
        "        raw_email = msg_data[0][1]\n",
        "        msg = email.message_from_bytes(raw_email)\n",
        "\n",
        "        # Decode email body\n",
        "        body = \"\"\n",
        "        if msg.is_multipart():\n",
        "            for part in msg.walk():\n",
        "                if part.get_content_type() == 'text/plain':\n",
        "                    payload = part.get_payload(decode=True)\n",
        "                    detected_encoding = chardet.detect(payload)['encoding']\n",
        "                    body = payload.decode(detected_encoding or 'utf-8', errors='replace')\n",
        "                    break\n",
        "        else:\n",
        "            payload = msg.get_payload(decode=True)\n",
        "            detected_encoding = chardet.detect(payload)['encoding']\n",
        "            body = payload.decode(detected_encoding or 'utf-8', errors='replace')\n",
        "\n",
        "        # Check for each DN number in the body\n",
        "        for dn_number in dn_numbers:\n",
        "            if dn_number in body:\n",
        "                tracking_dict[dn_number] = fetch_stt_number(body)\n",
        "\n",
        "    return tracking_dict\n",
        "\n",
        "# Define the function to compute the expected stock entry date\n",
        "def calculate_expected_stock_entry_date(row):\n",
        "    try:\n",
        "        inv_date_dispatch_date = pd.to_datetime(row['Inv. date dispatch date'], dayfirst=True, errors='coerce')\n",
        "        if pd.notnull(inv_date_dispatch_date):\n",
        "            conf_dd_confirmed_dispatch_date = pd.to_datetime(row['Conf. DD confirmed dispatch date'], dayfirst=True, errors='coerce')\n",
        "            expected_dd_expected_to_be_dispatched = pd.to_datetime(row['Expected DD expecte to be dispatched'], dayfirst=True, errors='coerce')\n",
        "\n",
        "            if row['Dist. ch.'] == 'af VOR direct':\n",
        "                days_to_add = 10\n",
        "            elif row['Dist. ch.'] == 'VOR route':\n",
        "                days_to_add = 21\n",
        "            else:\n",
        "                days_to_add = 10\n",
        "\n",
        "            return inv_date_dispatch_date + timedelta(days=days_to_add)\n",
        "        return pd.NaT\n",
        "    except KeyError as e:\n",
        "        print(f\"Column not found: {e}\")\n",
        "        return pd.NaT\n",
        "\n",
        "# Apply the function to each row to create the new column\n",
        "df['expectedstockentrydate'] = df.apply(calculate_expected_stock_entry_date, axis=1)\n",
        "\n",
        "# Define the function to compute the status\n",
        "def determine_status(row):\n",
        "    inv_date_dispatch_date = pd.to_datetime(row.get('Inv. date dispatch date', None), dayfirst=True, errors='coerce')\n",
        "    conf_dd_confirmed_dispatch_date = pd.to_datetime(row.get('Conf. DD confirmed dispatch date', None), dayfirst=True, errors='coerce')\n",
        "    expected_dd_expected_to_be_dispatched = pd.to_datetime(row.get('Expected DD expecte to be dispatched', None), dayfirst=True, errors='coerce')\n",
        "\n",
        "    if pd.notnull(inv_date_dispatch_date):\n",
        "        return f'invoice dispatch date on {inv_date_dispatch_date.strftime(\"%d/%m/%Y\")}'\n",
        "    elif pd.notnull(conf_dd_confirmed_dispatch_date):\n",
        "        return f'confirmed dispatch date on {conf_dd_confirmed_dispatch_date.strftime(\"%d/%m/%Y\")}'\n",
        "    elif pd.notnull(expected_dd_expected_to_be_dispatched):\n",
        "        return 'backorder'\n",
        "    else:\n",
        "        return 'backorder'\n",
        "\n",
        "# Apply the function to create the new status column\n",
        "df['status'] = df.apply(determine_status, axis=1)\n",
        "\n",
        "# Update status for rejected items\n",
        "df.loc[(df['Items status'] == 'Rejected') & (df['status'] == 'backorder'), 'status'] = 'Rejected'\n",
        "\n",
        "# Create the list_of_backorders column for searching\n",
        "def determine_backorders(row):\n",
        "    inv_date_dispatch_date = pd.to_datetime(row.get('Inv. date dispatch date', None), dayfirst=True, errors='coerce')\n",
        "    conf_dd_confirmed_dispatch_date = pd.to_datetime(row.get('Conf. DD confirmed dispatch date', None), dayfirst=True, errors='coerce')\n",
        "    expected_dd_expected_to_be_dispatched = pd.to_datetime(row.get('Expected DD expecte to be dispatched', None), dayfirst=True, errors='coerce')\n",
        "\n",
        "    if pd.isnull(inv_date_dispatch_date) and pd.isnull(conf_dd_confirmed_dispatch_date) and (pd.notnull(expected_dd_expected_to_be_dispatched) or pd.isnull(expected_dd_expected_to_be_dispatched)):\n",
        "        return 'backorders'\n",
        "    else:\n",
        "        return ''\n",
        "\n",
        "# Apply the function to create the new list_of_backorders column\n",
        "df['list_of_backorders'] = df.apply(determine_backorders, axis=1)\n",
        "\n",
        "# Filter out 'Rejected' items when searching for backorders\n",
        "filtered_df = df[(df['status'] == 'backorder') & (df['list_of_backorders'] == 'backorders')]\n",
        "\n",
        "# Get the list of DN numbers from the DataFrame\n",
        "dn_numbers = df['DN no.'].dropna().astype(str).tolist()\n",
        "\n",
        "# Search for tracking numbers in emails\n",
        "tracking_dict = search_emails_for_tracking_numbers(dn_numbers)\n",
        "\n",
        "# Update the existing entries with the tracking numbers\n",
        "df['Tracking No'] = df['DN no.'].map(tracking_dict)\n",
        "\n",
        "# Create the tracking details column\n",
        "df['tracking_details'] = df['Tracking No'].apply(lambda x: f'https://dbschenker.com/app/tracking-public/?refNumber={x}' if x != 'Not Found' else '')\n",
        "\n",
        "# Set tracking_details to blank if the value contains 'nan'\n",
        "df['tracking_details'] = df['tracking_details'].apply(lambda x: '' if 'nan' in x else x)\n",
        "\n",
        "# Set StockEntryDate to NaT where status is 'backorder' or 'Rejected'\n",
        "df.loc[df['status'].isin(['backorder', 'Rejected']), 'StockEntryDate'] = pd.NaT\n",
        "\n",
        "# Save results to a new Excel file\n",
        "df.to_excel(output_file, index=False)\n",
        "print(f\"Updated file saved to {output_file}\")\n",
        "\n",
        "# Close the connection and logout\n",
        "mail.close()\n",
        "mail.logout()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fX-V1p36YG6k",
        "outputId": "b2fd29ba-a302-44ac-f0c9-9ede4302d3c4",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the customer info: girne\n",
            "Customer info Details:\n",
            "       ±     gATP  Code Cust. No.  Cust. order no.              Part number  \\\n",
            "624   ⊞    Green   C21   CY822025         42871473  A 222 905 5111     9051   \n",
            "625   ⊞    Green   C21   CY822025         42871473  A 222 905 0309     9051   \n",
            "626   ⊞    Green   C21   CY822025         42871473  A 213 905 4803     9051   \n",
            "1114  ⊞   Yellow   C22   CY822025         42621444           A 222 899 0600   \n",
            "1115  ⊞    Green         CY822025         42621444           A 270 200 0200   \n",
            "1116  ⊞    Green         CY822025         42621444           A 205 330 5801   \n",
            "1117  ⊞    Green         CY822025         42621444           A 002 990 2017   \n",
            "1118  ⊞    Green         CY822025         42621444           A 210 501 0615   \n",
            "1119  ⊞    Green         CY822025         42621444           A 654 094 0204   \n",
            "1121  ⊞    Green         CY822025         42621444           A 169 540 1617   \n",
            "1132  ⊞   Yellow   C22   CY822025         42621444           A 222 899 0600   \n",
            "1133  ⊞    Green         CY822025         42621444           A 024 997 1045   \n",
            "1134  ⊞    Green         CY822025         42621444       A 000 997 3807  64   \n",
            "1136  ⊞    Green         CY822025         42621444           A 177 820 9900   \n",
            "1403  ⊞    Green         CY822025         42521426           A 205 501 7601   \n",
            "1404  ⊞    Green         CY822025         42521426           A 205 501 1001   \n",
            "1405  ⊞    Green         CY822025         42521426           A 205 501 1001   \n",
            "1864  ⊞    Green         CY822025         42361406           A 223 421 4200   \n",
            "1865  ⊞    Green         CY822025         42361406           A 223 824 0100   \n",
            "1867  ⊞    Green   C21   CY822025         42361406       A 000 905 8011  80   \n",
            "2371  ⊞   Yellow         CY822025         42271358           A 000 828 0388   \n",
            "2414  ⊞    Green         CY822025         42271358           A 231 905 0014   \n",
            "2415  ⊞    Green         CY822025         42271358           A 447 420 6600   \n",
            "2416  ⊞    Green         CY822025         42271358           A 447 420 6700   \n",
            "2892  ⊞   Yellow         CY822025         42201347           A 223 421 4200   \n",
            "3774  ⊞   Yellow         CY822025         42031303           A 222 899 0600   \n",
            "3777  ⊞    Green         CY822025         42031303           A 006 997 1890   \n",
            "3778  ⊞    Green         CY822025         42031303           A 169 540 1617   \n",
            "3779  ⊞    Green         CY822025         42031303           A 274 070 3500   \n",
            "3781  ⊞    Green         CY822025         42031303           A 270 159 0600   \n",
            "3783  ⊞    Green         CY822025         42031303           A 222 330 0107   \n",
            "3784  ⊞    Green         CY822025         42031303           A 222 330 0207   \n",
            "\n",
            "     Designation of part no. Ordered Designation of part no. Confirmed  \\\n",
            "624                     SWITCH BLOCK                      SWITCH BLOCK   \n",
            "625                     SWITCH BLOCK                      SWITCH BLOCK   \n",
            "626                     SWITCH BLOCK                      SWITCH BLOCK   \n",
            "1114                          FLACON                            FLACON   \n",
            "1115        COOLANT INLET CONNECTION          COOLANT INLET CONNECTION   \n",
            "1116                     SPRING LINK                       SPRING LINK   \n",
            "1117                      SCREW PLUG                        SCREW PLUG   \n",
            "1118                     CLOSING CAP                       CLOSING CAP   \n",
            "1119              AIR FILTER ELEMENT                AIR FILTER ELEMENT   \n",
            "1121            BRAKEPAD WEAR SENSOR              BRAKEPAD WEAR SENSOR   \n",
            "1132                          FLACON                            FLACON   \n",
            "1133                          O-RING                            O-RING   \n",
            "1134                          O-RING                            O-RING   \n",
            "1136          PARTS KIT, WIPER BLADE            PARTS KIT, WIPER BLADE   \n",
            "1403                      BLEED LINE                        BLEED LINE   \n",
            "1404                      BLEED LINE                        BLEED LINE   \n",
            "1405                      BLEED LINE                        BLEED LINE   \n",
            "1864              BRAKE DISK, VENTED                BRAKE DISK, VENTED   \n",
            "1865          PARTS KIT, WIPER BLADE            PARTS KIT, WIPER BLADE   \n",
            "1867                      NOX SENSOR                        NOX SENSOR   \n",
            "2371                    BATTERY PACK                      BATTERY PACK   \n",
            "2414            BRAKEPAD WEAR SENSOR              BRAKEPAD WEAR SENSOR   \n",
            "2415             PARTS KIT, BRAKEPAD               PARTS KIT, BRAKEPAD   \n",
            "2416             PARTS KIT, BRAKEPAD               PARTS KIT, BRAKEPAD   \n",
            "2892              BRAKE DISK, VENTED                BRAKE DISK, VENTED   \n",
            "3774                          FLACON                            FLACON   \n",
            "3777                      HOSE CLAMP                        HOSE CLAMP   \n",
            "3778            BRAKEPAD WEAR SENSOR              BRAKEPAD WEAR SENSOR   \n",
            "3779                       FUEL HOSE                         FUEL HOSE   \n",
            "3781                      SPARK PLUG                        SPARK PLUG   \n",
            "3783                     SPRING LINK                       SPRING LINK   \n",
            "3784                     SPRING LINK                       SPRING LINK   \n",
            "\n",
            "                Ord. date Items status  ...  M code Shelf life  \\\n",
            "624   13/08/2024 12:48 pm    Completed  ...  1PV546        NaN   \n",
            "625   13/08/2024 12:48 pm    Completed  ...  1PV546        NaN   \n",
            "626   13/08/2024 12:48 pm    Completed  ...  1PV543        NaN   \n",
            "1114  25/07/2024 05:51 pm    Completed  ...  1PZ733        NaN   \n",
            "1115  25/07/2024 05:51 pm    Completed  ...  1PV141        NaN   \n",
            "1116  25/07/2024 05:51 pm    Completed  ...  1PV032        NaN   \n",
            "1117  25/07/2024 05:51 pm    Completed  ...  1PV980        NaN   \n",
            "1118  25/07/2024 05:51 pm    Completed  ...  1PV176        NaN   \n",
            "1119  25/07/2024 05:51 pm    Completed  ...  1PW130        NaN   \n",
            "1121  25/07/2024 05:51 pm    Completed  ...  1PV413        NaN   \n",
            "1132  25/07/2024 05:51 pm    Completed  ...  1PZ733        NaN   \n",
            "1133  25/07/2024 05:51 pm    Completed  ...  1PV986        NaN   \n",
            "1134  25/07/2024 05:51 pm    Completed  ...  1PV986        NaN   \n",
            "1136  25/07/2024 05:51 pm    Completed  ...  1PV565        NaN   \n",
            "1403  11/07/2024 01:03 pm    Completed  ...  1PV517        NaN   \n",
            "1404  11/07/2024 01:03 pm    Completed  ...  1PV517        NaN   \n",
            "1405  11/07/2024 01:03 pm    Completed  ...  1PV517        NaN   \n",
            "1864  15/06/2024 04:13 pm    Completed  ...  1PV425        NaN   \n",
            "1865  15/06/2024 04:13 pm    Completed  ...  1PV565        NaN   \n",
            "1867  15/06/2024 04:13 pm    Completed  ...  1PE547        NaN   \n",
            "2371  29/05/2024 11:00 am    Completed  ...  1OX000      120.0   \n",
            "2414  23/05/2024 11:21 am    Completed  ...  1PV413        NaN   \n",
            "2415  23/05/2024 11:21 am    Completed  ...  2TV415        NaN   \n",
            "2416  23/05/2024 11:21 am    Completed  ...  2TV415        NaN   \n",
            "2892  13/05/2024 06:22 pm    Completed  ...  1PV425        NaN   \n",
            "3774  09/04/2024 02:41 pm    Completed  ...  1PZ733        NaN   \n",
            "3777  09/04/2024 02:41 pm    Completed  ...  1PV981        NaN   \n",
            "3778  09/04/2024 02:41 pm    Completed  ...  1PV413        NaN   \n",
            "3779  09/04/2024 02:41 pm    Completed  ...  1PV637        NaN   \n",
            "3781  09/04/2024 02:41 pm    Completed  ...  1PV580        NaN   \n",
            "3783  09/04/2024 02:41 pm    Completed  ...  1PV032        NaN   \n",
            "3784  09/04/2024 02:41 pm    Completed  ...  1PV032        NaN   \n",
            "\n",
            "     Return excluded DRT ID Request no. Hub ind. CON Costing code  \\\n",
            "624                     NaN         NaN       X  NaN          NaN   \n",
            "625                     NaN         NaN       X  NaN          NaN   \n",
            "626                     NaN         NaN       X  NaN          NaN   \n",
            "1114              X     NaN         NaN       X  NaN          NaN   \n",
            "1115                    NaN         NaN       X  NaN          NaN   \n",
            "1116                    NaN         NaN       X  NaN          NaN   \n",
            "1117                    NaN         NaN       X  NaN          NaN   \n",
            "1118                    NaN         NaN       X  NaN          NaN   \n",
            "1119                    NaN         NaN       X  NaN          NaN   \n",
            "1121                    NaN         NaN       X  NaN          NaN   \n",
            "1132              X     NaN         NaN       X  NaN          NaN   \n",
            "1133                    NaN         NaN       X  NaN          NaN   \n",
            "1134                    NaN         NaN       X  NaN          NaN   \n",
            "1136                    NaN         NaN       X  NaN          NaN   \n",
            "1403                    NaN         NaN       X  NaN          NaN   \n",
            "1404                    NaN         NaN       X  NaN          NaN   \n",
            "1405                    NaN         NaN       X  NaN          NaN   \n",
            "1864                    NaN         NaN       X  NaN          NaN   \n",
            "1865                    NaN         NaN       X  NaN          NaN   \n",
            "1867              X     NaN         NaN       X  NaN          NaN   \n",
            "2371              X     NaN         NaN          NaN          NaN   \n",
            "2414                    NaN         NaN       X  NaN          NaN   \n",
            "2415                    NaN         NaN       X  NaN          NaN   \n",
            "2416                    NaN         NaN       X  NaN          NaN   \n",
            "2892                    NaN         NaN       X  NaN          NaN   \n",
            "3774              X     NaN         NaN       X  NaN          NaN   \n",
            "3777                    NaN         NaN       X  NaN          NaN   \n",
            "3778                    NaN         NaN       X  NaN          NaN   \n",
            "3779                    NaN         NaN       X  NaN          NaN   \n",
            "3781                    NaN         NaN       X  NaN          NaN   \n",
            "3783                    NaN         NaN       X  NaN          NaN   \n",
            "3784                    NaN         NaN       X  NaN          NaN   \n",
            "\n",
            "     Situation report Cleaned Customer info  \n",
            "624               NaN                 GIRNE  \n",
            "625               NaN                 GIRNE  \n",
            "626               NaN                 GIRNE  \n",
            "1114              NaN                 GIRNE  \n",
            "1115              NaN                 GIRNE  \n",
            "1116              NaN                 GIRNE  \n",
            "1117              NaN                 GIRNE  \n",
            "1118              NaN                 GIRNE  \n",
            "1119              NaN                 GIRNE  \n",
            "1121              NaN                 GIRNE  \n",
            "1132              NaN                 GIRNE  \n",
            "1133              NaN                 GIRNE  \n",
            "1134              NaN                 GIRNE  \n",
            "1136              NaN                 GIRNE  \n",
            "1403              NaN                 GIRNE  \n",
            "1404              NaN                 GIRNE  \n",
            "1405              NaN                 GIRNE  \n",
            "1864              NaN                 GIRNE  \n",
            "1865              NaN                 GIRNE  \n",
            "1867              NaN                 GIRNE  \n",
            "2371              NaN                 GIRNE  \n",
            "2414              NaN                 GIRNE  \n",
            "2415              NaN                 GIRNE  \n",
            "2416              NaN                 GIRNE  \n",
            "2892              NaN                 GIRNE  \n",
            "3774              NaN                 GIRNE  \n",
            "3777              NaN                 GIRNE  \n",
            "3778              NaN                 GIRNE  \n",
            "3779              NaN                 GIRNE  \n",
            "3781              NaN                 GIRNE  \n",
            "3783              NaN                 GIRNE  \n",
            "3784              NaN                 GIRNE  \n",
            "\n",
            "[32 rows x 63 columns]\n",
            "Merged data has been saved to /content/cgniv_StarOrderplus_Order_items.xlsx\n",
            "Number of rows in the original df2 file: 2509\n",
            "Number of rows in the result file: 2509\n",
            "Updated file saved to /content/vaugzcstcketrd_expstckentryd_status_trcklnk_trckno.xlsx\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('BYE', [b'LOGOUT Requested'])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*** WORKS CONFIRMED 20/01/25 USE THIS Updated does not recognize tags behind customer info including -i and /G (fixed) 10/09/2024  can also be used for the new logbus output fıle ef update_order_items.  (can also be used  for the new logbus sıte, take sameıfles updated _order and merc_yedek_parca 07_01_25)***    "
      ],
      "metadata": {
        "id": "vvPkGqi2Ar-g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from datetime import timedelta\n",
        "import imaplib\n",
        "import email\n",
        "from email.header import decode_header\n",
        "import chardet\n",
        "import re\n",
        "\n",
        "# Email account credentials\n",
        "username = 'kombosawb@gmail.com'\n",
        "password = 'kyka ypey hfar rjvg'  # Use the App Password here\n",
        "\n",
        "# File paths for input Excel files\n",
        "file_path = '/content/updated_Order_items (43).xlsx'\n",
        "file_path1 = '/content/updated_Mercedes_Yedek_Parça_Sipariş_2024 (43).xlsx'\n",
        "file_path2 = '/content/niv_StarOrderplus_Order_items_new.xlsx'\n",
        "input_file = '/content/cgniv_StarOrderplus_Order_items.xlsx'\n",
        "\n",
        "# File path for the output Excel file\n",
        "output_file = '/content/vaugzcstcketrd_expstckentryd_status_trcklnk_trckno.xlsx'\n",
        "exdf1 = '/content/df1_unique.xlsx'\n",
        "exdf2 = '/content/df2.xlsx'\n",
        "\n",
        "# Load and clean the first Excel file\n",
        "df = pd.read_excel(file_path)\n",
        "\n",
        "# Create 'Cleaned Customer info' column by removing spaces, unwanted characters, and suffixes like '-i', '/G', etc.\n",
        "if 'Customer info' in df.columns:\n",
        "    # Updated regex to handle various suffixes including special characters\n",
        "    df['Cleaned Customer info'] = df['Customer info'].astype(str).str.replace(' ', '').str.upper().str.replace(r'[-/][A-ZİÝIi]+$', '', regex=True)\n",
        "else:\n",
        "    print(\"The column 'Customer info' was not found in the file.\")\n",
        "    df['Cleaned Customer info'] = df['Customer info']\n",
        "\n",
        "# Remove rows with unwanted 'Customer info' entries\n",
        "df_cleaned = df[~df['Cleaned Customer info'].str.lower().str.startswith(('stok', 'stpk', 'minarelikoy', 'mýna', 'stock', 'raf')) &\n",
        "                ~df['Cleaned Customer info'].str.startswith(('RAF', 'STOCKMT'))]\n",
        "\n",
        "# Save the cleaned DataFrame to a new Excel file\n",
        "df_cleaned.to_excel(file_path2, index=False)\n",
        "\n",
        "# Function to get customer info details\n",
        "def get_customer_info_details():\n",
        "    customer_info_input = input(\"Enter the customer info: \").strip()\n",
        "    if 'Cleaned Customer info' in df_cleaned.columns:\n",
        "        part_details = df_cleaned[df_cleaned['Cleaned Customer info'].astype(str).str.contains(customer_info_input, case=False, na=False)]\n",
        "    else:\n",
        "        print(\"The column 'Cleaned Customer info' was not found in the cleaned file.\")\n",
        "        return\n",
        "\n",
        "    if not part_details.empty:\n",
        "        print(\"Customer info Details:\")\n",
        "        print(part_details)\n",
        "    else:\n",
        "        print(\"No details found for the entered customer info.\")\n",
        "\n",
        "# Run the function\n",
        "get_customer_info_details()\n",
        "\n",
        "# Load the cleaned DataFrame and other Excel files\n",
        "df_cleaned = pd.read_excel(file_path2)\n",
        "df1 = pd.read_excel(file_path1)\n",
        "df2 = pd.read_excel(file_path2)\n",
        "\n",
        "# Check for required columns in df1 and df2\n",
        "required_columns = {'Customer info', 'Part number'}\n",
        "missing_columns_df1 = required_columns - set(df1.columns)\n",
        "missing_columns_df2 = required_columns - set(df2.columns)\n",
        "\n",
        "if missing_columns_df1:\n",
        "    print(f\"The following required columns are missing in the first file: {missing_columns_df1}\")\n",
        "if missing_columns_df2:\n",
        "    print(f\"The following required columns are missing in the second file: {missing_columns_df2}\")\n",
        "\n",
        "if not missing_columns_df1 and not missing_columns_df2:\n",
        "    # Clean 'Part number' columns in df1 and df2\n",
        "    df1['Cleaned Part number'] = df1['Part number'].astype(str).str.replace(' ', '').str.upper().str[:10]\n",
        "    df2['Cleaned Part number'] = df2['Part number'].astype(str).str.replace(' ', '').str.upper().str[:10]\n",
        "\n",
        "    # Clean 'Customer info' columns in df1\n",
        "    df1['Cleaned Customer info'] = df1['Customer info'].astype(str).str.replace(' ', '').str.upper().str.replace(r'[-/][A-ZİÝIi]+$', '', regex=True)\n",
        "    df1_unique = df1.drop_duplicates(subset=['Cleaned Customer info', 'Cleaned Part number'])\n",
        "\n",
        "    # Save df1_unique for verification\n",
        "    df1_unique.to_excel(exdf1, index=False)\n",
        "\n",
        "\n",
        "    # Clean 'Customer info' columns in df2\n",
        "    df2['Cleaned Customer info'] = df2['Customer info'].astype(str).str.replace(' ', '').str.upper().str.replace(r'[-/][A-ZİÝIi]+$', '', regex=True)\n",
        "\n",
        "    # Merge 'StockEntryDate' from df1_unique into df2 based on cleaned columns\n",
        "    merged_df = pd.merge(df2, df1_unique[['Cleaned Customer info', 'Cleaned Part number', 'StockEntryDate']],\n",
        "                         on=['Cleaned Customer info', 'Cleaned Part number'], how='left')\n",
        "\n",
        "    # Save the resulting DataFrame\n",
        "    merged_df.to_excel(input_file, index=False)\n",
        "    print(f\"Merged data has been saved to {input_file}\")\n",
        "    print(f\"Number of rows in the original df2 file: {len(df2)}\")\n",
        "    print(f\"Number of rows in the result file: {len(merged_df)}\")\n",
        "\n",
        "else:\n",
        "    print(\"One or both required columns 'Customer info' or 'Part number' were not found in the provided files.\")\n",
        "\n",
        "# Load the updated DataFrame\n",
        "df = pd.read_excel(input_file)\n",
        "\n",
        "# Connect to the email server\n",
        "mail = imaplib.IMAP4_SSL('imap.gmail.com')\n",
        "\n",
        "def fetch_stt_number(body):\n",
        "    stt_number_match = re.search(r'STT Number[:\\.\\s]+(\\d+)', body)\n",
        "    return stt_number_match.group(1) if stt_number_match else 'Not Found'\n",
        "\n",
        "def search_emails_for_tracking_numbers(dn_numbers):\n",
        "    tracking_dict = {dn_number: 'Not Found' for dn_number in dn_numbers}\n",
        "    mail.login(username, password)\n",
        "    mail.select('inbox')\n",
        "\n",
        "    result, data = mail.search(None, 'ALL')\n",
        "    if result != 'OK':\n",
        "        print(\"Failed to search for emails.\")\n",
        "        return tracking_dict\n",
        "\n",
        "    email_ids = data[0].split()\n",
        "    for email_id in email_ids:\n",
        "        result, msg_data = mail.fetch(email_id, '(RFC822)')\n",
        "        if result != 'OK':\n",
        "            print(f\"Failed to fetch email with ID {email_id}\")\n",
        "            continue\n",
        "\n",
        "        raw_email = msg_data[0][1]\n",
        "        msg = email.message_from_bytes(raw_email)\n",
        "\n",
        "        # Decode email body\n",
        "        body = \"\"\n",
        "        if msg.is_multipart():\n",
        "            for part in msg.walk():\n",
        "                if part.get_content_type() == 'text/plain':\n",
        "                    payload = part.get_payload(decode=True)\n",
        "                    detected_encoding = chardet.detect(payload)['encoding']\n",
        "                    body = payload.decode(detected_encoding or 'utf-8', errors='replace')\n",
        "                    break\n",
        "        else:\n",
        "            payload = msg.get_payload(decode=True)\n",
        "            detected_encoding = chardet.detect(payload)['encoding']\n",
        "            body = payload.decode(detected_encoding or 'utf-8', errors='replace')\n",
        "\n",
        "        # Check for each DN number in the body\n",
        "        for dn_number in dn_numbers:\n",
        "            if dn_number in body:\n",
        "                tracking_dict[dn_number] = fetch_stt_number(body)\n",
        "\n",
        "    return tracking_dict\n",
        "\n",
        "# Define the function to compute the expected stock entry date\n",
        "def calculate_expected_stock_entry_date(row):\n",
        "    try:\n",
        "        inv_date_dispatch_date = pd.to_datetime(row['Inv. date dispatch date'], dayfirst=True, errors='coerce')\n",
        "        if pd.notnull(inv_date_dispatch_date):\n",
        "            conf_dd_confirmed_dispatch_date = pd.to_datetime(row['Conf. DD confirmed dispatch date'], dayfirst=True, errors='coerce')\n",
        "            expected_dd_expected_to_be_dispatched = pd.to_datetime(row['Expected DD expecte to be dispatched'], dayfirst=True, errors='coerce')\n",
        "\n",
        "            if row['Dist. ch.'] == 'af VOR direct':\n",
        "                days_to_add = 10\n",
        "            elif row['Dist. ch.'] == 'VOR route':\n",
        "                days_to_add = 21\n",
        "            else:\n",
        "                days_to_add = 10\n",
        "\n",
        "            return inv_date_dispatch_date + timedelta(days=days_to_add)\n",
        "        return pd.NaT\n",
        "    except KeyError as e:\n",
        "        print(f\"Column not found: {e}\")\n",
        "        return pd.NaT\n",
        "\n",
        "# Apply the function to each row to create the new column\n",
        "df['expectedstockentrydate'] = df.apply(calculate_expected_stock_entry_date, axis=1)\n",
        "\n",
        "# Define the function to compute the status\n",
        "def determine_status(row):\n",
        "    inv_date_dispatch_date = pd.to_datetime(row.get('Inv. date dispatch date', None), dayfirst=True, errors='coerce')\n",
        "    conf_dd_confirmed_dispatch_date = pd.to_datetime(row.get('Conf. DD confirmed dispatch date', None), dayfirst=True, errors='coerce')\n",
        "    expected_dd_expected_to_be_dispatched = pd.to_datetime(row.get('Expected DD expecte to be dispatched', None), dayfirst=True, errors='coerce')\n",
        "\n",
        "    if pd.notnull(inv_date_dispatch_date):\n",
        "        return f'invoice dispatch date on {inv_date_dispatch_date.strftime(\"%d/%m/%Y\")}'\n",
        "    elif pd.notnull(conf_dd_confirmed_dispatch_date):\n",
        "        return f'confirmed dispatch date on {conf_dd_confirmed_dispatch_date.strftime(\"%d/%m/%Y\")}'\n",
        "    elif pd.notnull(expected_dd_expected_to_be_dispatched):\n",
        "        return 'backorder'\n",
        "    else:\n",
        "        return 'backorder'\n",
        "\n",
        "# Apply the function to create the new status column\n",
        "df['status'] = df.apply(determine_status, axis=1)\n",
        "\n",
        "# Update status for rejected items\n",
        "df.loc[(df['Items status'] == 'Rejected') & (df['status'] == 'backorder'), 'status'] = 'Rejected'\n",
        "\n",
        "# Create the list_of_backorders column for searching\n",
        "def determine_backorders(row):\n",
        "    inv_date_dispatch_date = pd.to_datetime(row.get('Inv. date dispatch date', None), dayfirst=True, errors='coerce')\n",
        "    conf_dd_confirmed_dispatch_date = pd.to_datetime(row.get('Conf. DD confirmed dispatch date', None), dayfirst=True, errors='coerce')\n",
        "    expected_dd_expected_to_be_dispatched = pd.to_datetime(row.get('Expected DD expecte to be dispatched', None), dayfirst=True, errors='coerce')\n",
        "\n",
        "    if pd.isnull(inv_date_dispatch_date) and pd.isnull(conf_dd_confirmed_dispatch_date) and (pd.notnull(expected_dd_expected_to_be_dispatched) or pd.isnull(expected_dd_expected_to_be_dispatched)):\n",
        "        return 'backorders'\n",
        "    else:\n",
        "        return ''\n",
        "\n",
        "# Apply the function to create the new list_of_backorders column\n",
        "df['list_of_backorders'] = df.apply(determine_backorders, axis=1)\n",
        "\n",
        "# Filter out 'Rejected' items when searching for backorders\n",
        "filtered_df = df[(df['status'] == 'backorder') & (df['list_of_backorders'] == 'backorders')]\n",
        "\n",
        "# Get the list of DN numbers from the DataFrame\n",
        "dn_numbers = df['DN no.'].dropna().astype(str).tolist()\n",
        "\n",
        "# Search for tracking numbers in emails\n",
        "tracking_dict = search_emails_for_tracking_numbers(dn_numbers)\n",
        "\n",
        "# Update the existing entries with the tracking numbers\n",
        "df['Tracking No'] = df['DN no.'].map(tracking_dict)\n",
        "\n",
        "# Create the tracking details column\n",
        "df['tracking_details'] = df['Tracking No'].apply(lambda x: f'https://dbschenker.com/app/tracking-public/?refNumber={x}' if x != 'Not Found' else '')\n",
        "\n",
        "# Set tracking_details to blank if the value contains 'nan'\n",
        "df['tracking_details'] = df['tracking_details'].apply(lambda x: '' if 'nan' in x else x)\n",
        "\n",
        "# Set StockEntryDate to NaT where status is 'backorder' or 'Rejected'\n",
        "df.loc[df['status'].isin(['backorder', 'Rejected']), 'StockEntryDate'] = pd.NaT\n",
        "\n",
        "# Save results to a new Excel file\n",
        "df.to_excel(output_file, index=False)\n",
        "print(f\"Updated file saved to {output_file}\")\n",
        "\n",
        "# Close the connection and logout\n",
        "mail.close()\n",
        "mail.logout()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_LNktTs33jC",
        "outputId": "365143fc-d88b-468b-f2dc-6c0c25603cd0",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the customer info: Girne\n",
            "Customer info Details:\n",
            "       ±    gATP  Code Cust. No.  Cust. order no.     Part number  \\\n",
            "183   ⊞   Green         CY822025         44051755  A 270 159 0600   \n",
            "184   ⊞   Green         CY822025         44051755  A 004 159 5803   \n",
            "185   ⊞   Green         CY822025         44051755  A 271 016 1221   \n",
            "186   ⊞   Green         CY822025         44051755  A 271 016 1321   \n",
            "189   ⊞     Red   C21   CY822025         44051755  A 004 994 1845   \n",
            "...   ..     ...   ...       ...              ...             ...   \n",
            "3178  ⊞   Green         CY822025         43281568  A 223 835 2300   \n",
            "4086  ⊞   Green         CY822025         43041533  A 270 200 0200   \n",
            "4095  ⊞   Green         CY822025         43041533  A 222 899 0600   \n",
            "4103  ⊞   Green         CY822025         43041533  A 447 880 1114   \n",
            "4104  ⊞   Green         CY822025         43041533  A 447 880 1214   \n",
            "\n",
            "     Designation of part no. Ordered Designation of part no. Confirmed  \\\n",
            "183                       SPARK PLUG                        SPARK PLUG   \n",
            "184                       SPARK PLUG                        SPARK PLUG   \n",
            "185        SEAL, CYLINDER HEAD COVER         SEAL, CYLINDER HEAD COVER   \n",
            "186        SEAL, CYLINDER HEAD COVER         SEAL, CYLINDER HEAD COVER   \n",
            "189                  SPRING LOCK NUT                   SPRING LOCK NUT   \n",
            "...                              ...                               ...   \n",
            "3178                     DUST FILTER                       DUST FILTER   \n",
            "4086        COOLANT INLET CONNECTION          COOLANT INLET CONNECTION   \n",
            "4095                          FLACON                            FLACON   \n",
            "4103                          HOLDER                            HOLDER   \n",
            "4104                          HOLDER                            HOLDER   \n",
            "\n",
            "                Ord. date Items status  ...  M code Shelf life  \\\n",
            "183   15/01/2025 11:29 am    Completed  ...  1PV580        NaN   \n",
            "184   15/01/2025 11:29 am    Completed  ...  1PV580        NaN   \n",
            "185   15/01/2025 11:29 am    Completed  ...  1PV105        NaN   \n",
            "186   15/01/2025 11:29 am    Completed  ...  1PV105        NaN   \n",
            "189   15/01/2025 11:29 am         Open  ...  1PV981        NaN   \n",
            "...                   ...          ...  ...     ...        ...   \n",
            "3178  03/10/2024 05:48 pm    Completed  ...  1PW660        NaN   \n",
            "4086  12/09/2024 06:21 pm    Completed  ...  1PV141        NaN   \n",
            "4095  12/09/2024 06:21 pm    Completed  ...  1PZ733        NaN   \n",
            "4103  12/09/2024 06:21 pm    Completed  ...  2TU622        NaN   \n",
            "4104  12/09/2024 06:21 pm    Completed  ...  2TU622        NaN   \n",
            "\n",
            "     Return excluded DRT ID Request no. Hub ind. CON Costing code  \\\n",
            "183                     NaN         NaN       X  NaN          NaN   \n",
            "184                     NaN         NaN       X  NaN          NaN   \n",
            "185                     NaN         NaN       X  NaN          NaN   \n",
            "186                     NaN         NaN       X  NaN          NaN   \n",
            "189                     NaN         NaN       X  NaN          NaN   \n",
            "...              ...    ...         ...      ...  ..          ...   \n",
            "3178                    NaN         NaN       X  NaN          NaN   \n",
            "4086                    NaN         NaN       X  NaN          NaN   \n",
            "4095              X     NaN         NaN       X  NaN          NaN   \n",
            "4103                    NaN         NaN       X  NaN          NaN   \n",
            "4104                    NaN         NaN       X  NaN          NaN   \n",
            "\n",
            "     Situation report Cleaned Customer info  \n",
            "183               NaN                 GIRNE  \n",
            "184               NaN                 GIRNE  \n",
            "185               NaN                 GIRNE  \n",
            "186               NaN                 GIRNE  \n",
            "189               NaN                 GIRNE  \n",
            "...               ...                   ...  \n",
            "3178              NaN                 GIRNE  \n",
            "4086              NaN                 GIRNE  \n",
            "4095              NaN                 GIRNE  \n",
            "4103              NaN                 GIRNE  \n",
            "4104              NaN                 GIRNE  \n",
            "\n",
            "[63 rows x 63 columns]\n",
            "Merged data has been saved to /content/cgniv_StarOrderplus_Order_items.xlsx\n",
            "Number of rows in the original df2 file: 3120\n",
            "Number of rows in the result file: 3120\n",
            "Updated file saved to /content/vaugzcstcketrd_expstckentryd_status_trcklnk_trckno.xlsx\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('BYE', [b'LOGOUT Requested'])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from datetime import timedelta\n",
        "import imaplib\n",
        "import email\n",
        "from email.header import decode_header\n",
        "import chardet\n",
        "import re\n",
        "\n",
        "# Email account credentials\n",
        "username = 'kombosawb@gmail.com'\n",
        "password = 'kyka ypey hfar rjvg'  # Use the App Password here\n",
        "\n",
        "# File paths for input Excel files\n",
        "file_path = '/content/updated_Order_items (38).xlsx'\n",
        "file_path1 = '/content/updated_Mercedes_Yedek_Parça_Sipariş_2024 (38).xlsx'\n",
        "file_path2 = '/content/niv_StarOrderplus_Order_items_new.xlsx'\n",
        "input_file = '/content/cgniv_StarOrderplus_Order_items.xlsx'\n",
        "\n",
        "# File path for the output Excel file\n",
        "output_file = '/content/vaugzcstcketrd_expstckentryd_status_trcklnk_trckno.xlsx'\n",
        "exdf1 = '/content/df1_unique.xlsx'\n",
        "exdf2 = '/content/df2.xlsx'\n",
        "\n",
        "# Load and clean the first Excel file\n",
        "df = pd.read_excel(file_path)\n",
        "\n",
        "# Create 'Cleaned Customer info' column by removing spaces, unwanted characters, and suffixes like '-i', '/G', etc.\n",
        "if 'Customer info' in df.columns:\n",
        "    # Updated regex to handle various suffixes including special characters\n",
        "    df['Cleaned Customer info'] = df['Customer info'].astype(str).str.replace(' ', '').str.upper().str.replace(r'[-/][A-ZİÝIi]+$', '', regex=True)\n",
        "else:\n",
        "    print(\"The column 'Customer info' was not found in the file.\")\n",
        "    df['Cleaned Customer info'] = df['Customer info']\n",
        "\n",
        "# Remove rows with unwanted 'Customer info' entries\n",
        "df_cleaned = df[~df['Cleaned Customer info'].str.lower().str.startswith(('stok', 'stpk', 'minarelikoy', 'mýna', 'stock', 'raf')) &\n",
        "                ~df['Cleaned Customer info'].str.startswith(('RAF', 'STOCKMT'))]\n",
        "\n",
        "# Save the cleaned DataFrame to a new Excel file\n",
        "df_cleaned.to_excel(file_path2, index=False)\n",
        "\n",
        "# Function to get customer info details\n",
        "def get_customer_info_details():\n",
        "    customer_info_input = input(\"Enter the customer info: \").strip()\n",
        "    if 'Cleaned Customer info' in df_cleaned.columns:\n",
        "        part_details = df_cleaned[df_cleaned['Cleaned Customer info'].astype(str).str.contains(customer_info_input, case=False, na=False)]\n",
        "    else:\n",
        "        print(\"The column 'Cleaned Customer info' was not found in the cleaned file.\")\n",
        "        return\n",
        "\n",
        "    if not part_details.empty:\n",
        "        print(\"Customer info Details:\")\n",
        "        print(part_details)\n",
        "    else:\n",
        "        print(\"No details found for the entered customer info.\")\n",
        "\n",
        "# Run the function\n",
        "get_customer_info_details()\n",
        "\n",
        "# Load the cleaned DataFrame and other Excel files\n",
        "df_cleaned = pd.read_excel(file_path2)\n",
        "df1 = pd.read_excel(file_path1)\n",
        "df2 = pd.read_excel(file_path2)\n",
        "\n",
        "# Check for required columns in df1 and df2\n",
        "required_columns = {'Customer info', 'Part number'}\n",
        "missing_columns_df1 = required_columns - set(df1.columns)\n",
        "missing_columns_df2 = required_columns - set(df2.columns)\n",
        "\n",
        "if missing_columns_df1:\n",
        "    print(f\"The following required columns are missing in the first file: {missing_columns_df1}\")\n",
        "if missing_columns_df2:\n",
        "    print(f\"The following required columns are missing in the second file: {missing_columns_df2}\")\n",
        "\n",
        "if not missing_columns_df1 and not missing_columns_df2:\n",
        "    # Clean 'Part number' columns in df1 and df2\n",
        "    df1['Cleaned Part number'] = df1['Part number'].astype(str).str.replace(' ', '').str.upper().str[:10]\n",
        "    df2['Cleaned Part number'] = df2['Part number'].astype(str).str.replace(' ', '').str.upper().str[:10]\n",
        "\n",
        "    # Clean 'Customer info' columns in df1\n",
        "    df1['Cleaned Customer info'] = df1['Customer info'].astype(str).str.replace(' ', '').str.upper().str.replace(r'[-/][A-ZİÝIi]+$', '', regex=True)\n",
        "    df1_unique = df1.drop_duplicates(subset=['Cleaned Customer info', 'Cleaned Part number'])\n",
        "\n",
        "    # Save df1_unique for verification\n",
        "    df1_unique.to_excel(exdf1, index=False)\n",
        "\n",
        "    # Clean 'Customer info' columns in df2\n",
        "    df2['Cleaned Customer info'] = df2['Customer info'].astype(str).str.replace(' ', '').str.upper().str.replace(r'[-/][A-ZİÝIi]+$', '', regex=True)\n",
        "\n",
        "    # Merge 'StockEntryDate' from df1_unique into df2 based on cleaned columns\n",
        "    merged_df = pd.merge(df2, df1_unique[['Cleaned Customer info', 'Cleaned Part number', 'StockEntryDate']],\n",
        "                         on=['Cleaned Customer info', 'Cleaned Part number'], how='left')\n",
        "\n",
        "    # Save the resulting DataFrame\n",
        "    merged_df.to_excel(input_file, index=False)\n",
        "    print(f\"Merged data has been saved to {input_file}\")\n",
        "    print(f\"Number of rows in the original df2 file: {len(df2)}\")\n",
        "    print(f\"Number of rows in the result file: {len(merged_df)}\")\n",
        "\n",
        "else:\n",
        "    print(\"One or both required columns 'Customer info' or 'Part number' were not found in the provided files.\")\n",
        "\n",
        "# Load the updated DataFrame\n",
        "df = pd.read_excel(input_file)\n",
        "\n",
        "# Connect to the email server\n",
        "mail = imaplib.IMAP4_SSL('imap.gmail.com')\n",
        "\n",
        "def fetch_stt_number(body):\n",
        "    stt_number_match = re.search(r'STT Number[:\\.\\s]+(\\d+)', body)\n",
        "    return stt_number_match.group(1) if stt_number_match else 'Not Found'\n",
        "\n",
        "def search_emails_for_tracking_numbers(dn_numbers):\n",
        "    tracking_dict = {dn_number: 'Not Found' for dn_number in dn_numbers}\n",
        "    mail.login(username, password)\n",
        "    mail.select('inbox')\n",
        "\n",
        "    result, data = mail.search(None, 'ALL')\n",
        "    if result != 'OK':\n",
        "        print(\"Failed to search for emails.\")\n",
        "        return tracking_dict\n",
        "\n",
        "    email_ids = data[0].split()\n",
        "    for email_id in email_ids:\n",
        "        result, msg_data = mail.fetch(email_id, '(RFC822)')\n",
        "        if result != 'OK':\n",
        "            print(f\"Failed to fetch email with ID {email_id}\")\n",
        "            continue\n",
        "\n",
        "        raw_email = msg_data[0][1]\n",
        "        msg = email.message_from_bytes(raw_email)\n",
        "\n",
        "        # Decode email body\n",
        "        body = \"\"\n",
        "        if msg.is_multipart():\n",
        "            for part in msg.walk():\n",
        "                if part.get_content_type() == 'text/plain':\n",
        "                    payload = part.get_payload(decode=True)\n",
        "                    detected_encoding = chardet.detect(payload)['encoding']\n",
        "                    body = payload.decode(detected_encoding or 'utf-8', errors='replace')\n",
        "                    break\n",
        "        else:\n",
        "            payload = msg.get_payload(decode=True)\n",
        "            detected_encoding = chardet.detect(payload)['encoding']\n",
        "            body = payload.decode(detected_encoding or 'utf-8', errors='replace')\n",
        "\n",
        "        # Check for each DN number in the body\n",
        "        for dn_number in dn_numbers:\n",
        "            if dn_number in body:\n",
        "                tracking_dict[dn_number] = fetch_stt_number(body)\n",
        "\n",
        "    return tracking_dict\n",
        "\n",
        "# Define the function to compute the expected stock entry date\n",
        "def calculate_expected_stock_entry_date(row):\n",
        "    try:\n",
        "        inv_date_dispatch_date = pd.to_datetime(row['Inv. date dispatch date'], dayfirst=True, errors='coerce')\n",
        "        if pd.notnull(inv_date_dispatch_date):\n",
        "            conf_dd_confirmed_dispatch_date = pd.to_datetime(row['Conf. DD confirmed dispatch date'], dayfirst=True, errors='coerce')\n",
        "            expected_dd_expected_to_be_dispatched = pd.to_datetime(row['Expected DD expecte to be dispatched'], dayfirst=True, errors='coerce')\n",
        "\n",
        "            if row['Dist. ch.'] == 'af VOR direct':\n",
        "                days_to_add = 10\n",
        "            elif row['Dist. ch.'] == 'VOR route':\n",
        "                days_to_add = 21\n",
        "            else:\n",
        "                days_to_add = 10\n",
        "\n",
        "            return inv_date_dispatch_date + timedelta(days=days_to_add)\n",
        "        return pd.NaT\n",
        "    except KeyError as e:\n",
        "        print(f\"Column not found: {e}\")\n",
        "        return pd.NaT\n",
        "\n",
        "# Apply the function to each row to create the new column\n",
        "df['expectedstockentrydate'] = df.apply(calculate_expected_stock_entry_date, axis=1)\n",
        "\n",
        "# Define the function to compute the status\n",
        "def determine_status(row):\n",
        "    inv_date_dispatch_date = pd.to_datetime(row.get('Inv. date dispatch date', None), dayfirst=True, errors='coerce')\n",
        "    conf_dd_confirmed_dispatch_date = pd.to_datetime(row.get('Conf. DD confirmed dispatch date', None), dayfirst=True, errors='coerce')\n",
        "    expected_dd_expected_to_be_dispatched = pd.to_datetime(row.get('Expected DD expecte to be dispatched', None), dayfirst=True, errors='coerce')\n",
        "\n",
        "    if pd.notnull(inv_date_dispatch_date):\n",
        "        return f'invoice dispatch date on {inv_date_dispatch_date.strftime(\"%d/%m/%Y\")}'\n",
        "    elif pd.notnull(conf_dd_confirmed_dispatch_date):\n",
        "        return f'confirmed dispatch date on {conf_dd_confirmed_dispatch_date.strftime(\"%d/%m/%Y\")}'\n",
        "    elif pd.notnull(expected_dd_expected_to_be_dispatched):\n",
        "        return 'backorder'\n",
        "    else:\n",
        "        return 'backorder'\n",
        "\n",
        "# Apply the function to create the new status column\n",
        "df['status'] = df.apply(determine_status, axis=1)\n",
        "\n",
        "# Update status for rejected items\n",
        "df.loc[(df['Items status'] == 'Rejected') & (df['status'] == 'backorder'), 'status'] = 'Rejected'\n",
        "\n",
        "# Create the list_of_backorders column for searching\n",
        "def determine_backorders(row):\n",
        "    inv_date_dispatch_date = pd.to_datetime(row.get('Inv. date dispatch date', None), dayfirst=True, errors='coerce')\n",
        "    conf_dd_confirmed_dispatch_date = pd.to_datetime(row.get('Conf. DD confirmed dispatch date', None), dayfirst=True, errors='coerce')\n",
        "    expected_dd_expected_to_be_dispatched = pd.to_datetime(row.get('Expected DD expecte to be dispatched', None), dayfirst=True, errors='coerce')\n",
        "\n",
        "    if pd.isnull(inv_date_dispatch_date) and pd.isnull(conf_dd_confirmed_dispatch_date) and (pd.notnull(expected_dd_expected_to_be_dispatched) or pd.isnull(expected_dd_expected_to_be_dispatched)):\n",
        "        return 'backorders'\n",
        "    else:\n",
        "        return ''\n",
        "\n",
        "# Apply the function to create the new list_of_backorders column\n",
        "df['list_of_backorders'] = df.apply(determine_backorders, axis=1)\n",
        "\n",
        "# Filter out 'Rejected' items when searching for backorders\n",
        "filtered_df = df[(df['status'] == 'backorder') & (df['list_of_backorders'] == 'backorders')]\n",
        "\n",
        "# Get the list of DN numbers from the DataFrame\n",
        "dn_numbers = df['DN no.'].dropna().astype(str).tolist()\n",
        "\n",
        "# Search for tracking numbers in emails\n",
        "tracking_dict = search_emails_for_tracking_numbers(dn_numbers)\n",
        "\n",
        "# Update the existing entries with the tracking numbers\n",
        "df['Tracking No'] = df['DN no.'].map(tracking_dict)\n",
        "\n",
        "# Create the tracking details column\n",
        "df['tracking_details'] = df['Tracking No'].apply(lambda x: f'https://dbschenker.com/app/tracking-public/?refNumber={x}' if x != 'Not Found' else '')\n",
        "\n",
        "# Set tracking_details to blank if the value contains 'nan'\n",
        "df['tracking_details'] = df['tracking_details'].apply(lambda x: '' if 'nan' in x else x)\n",
        "\n",
        "# Set StockEntryDate to NaT where status is 'backorder' or 'Rejected'\n",
        "df.loc[df['status'].isin(['backorder', 'Rejected']), 'StockEntryDate'] = pd.NaT\n",
        "\n",
        "# Save results to a new Excel file\n",
        "df.to_excel(output_file, index=False)\n",
        "print(f\"Updated file saved to {output_file}\")\n",
        "\n",
        "# Close the connection and logout\n",
        "mail.close()\n",
        "mail.logout()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "L2sFXtm2GW_y",
        "outputId": "1b340f10-daf1-4447-e3af-e6314a9a2019"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the customer info: girne\n",
            "Customer info Details:\n",
            "       ±     gATP  Code Cust. No.  Cust. order no.              Part number  \\\n",
            "5     ⊞   Yellow         CY822025         43931734          N 000000 004039   \n",
            "122   ⊞    Green         CY822025         43931734           A 447 420 6600   \n",
            "123   ⊞    Green         CY822025         43931734           A 447 420 6700   \n",
            "124   ⊞    Green         CY822025         43931734           A 654 094 1500   \n",
            "133   ⊞    Green         CY822025         43931734           A 002 990 2017   \n",
            "147   ⊞    Green         CY822025         43931734           A 906 540 1517   \n",
            "155   ⊞    Green         CY822025         43931734  A 247 584 3313     Z102   \n",
            "156   ⊞      Red         CY822025         43931734  A 206 584 6505     Z102   \n",
            "157   ⊞      Red         CY822025         43931734           A 243 814 0000   \n",
            "158   ⊞    Green         CY822025         43931734  A 177 680 8002     9G33   \n",
            "159   ⊞      Red         CY822025         43931734  A 247 680 0203     9G33   \n",
            "162   ⊞    Green         CY822025         43931734  A 465 680 1300     9051   \n",
            "163   ⊞    Green         CY822025         43931734           A 213 766 0600   \n",
            "164   ⊞      Red         CY822025         43931734  A 099 464 0013     9107   \n",
            "165   ⊞    Green         CY822025         43931734           A 622 017 0000   \n",
            "166   ⊞    Green         CY822025         43931734           A 654 094 1500   \n",
            "167   ⊞    Green         CY822025         43931734           A 271 180 0109   \n",
            "168   ⊞    Green         CY822025         43931734           A 271 180 0509   \n",
            "169   ⊞    Green         CY822025         43931734           A 271 094 0304   \n",
            "170   ⊞    Green         CY822025         43931734           A 271 094 0204   \n",
            "171   ⊞    Green         CY822025         43931734           A 607 997 0345   \n",
            "172   ⊞    Green         CY822025         43931734           A 231 905 0014   \n",
            "173   ⊞    Green         CY822025         43931734           A 164 540 1017   \n",
            "174   ⊞    Green         CY822025         43931734           A 169 540 1617   \n",
            "1264  ⊞    Green         CY822025         43681662           A 271 238 0380   \n",
            "1469  ⊞    Green         CY822025         43621640       A 447 421 0012  07   \n",
            "1470  ⊞    Green         CY822025         43621640       A 447 423 0012  07   \n",
            "1478  ⊞    Green   C21   CY822025         43621640           A 177 094 0000   \n",
            "1479  ⊞    Green   C21   CY822025         43621640           A 177 094 0100   \n",
            "1480  ⊞    Green         CY822025         43621640           A 278 180 0009   \n",
            "1481  ⊞    Green   C22   CY822025         43621640           A 642 090 5352   \n",
            "1482  ⊞    Green   C21   CY822025         43621640  A 205 905 6811     9051   \n",
            "1694  ⊞   Yellow         CY822025         43611630           A 094 990 8907   \n",
            "1700  ⊞      Red   C21   CY822025         43611630           A 004 994 1845   \n",
            "1701  ⊞    Green         CY822025         43611630           A 654 094 0004   \n",
            "1900  ⊞   Yellow         CY822025         43561612           A 000 828 0388   \n",
            "2033  ⊞    Green   C21   CY822025         43561615  A 205 905 6811     9051   \n",
            "2034  ⊞    Green   C21   CY822025         43561615           A 212 830 0242   \n",
            "2035  ⊞    Green         CY822025         43561615       A 000 997 3807  64   \n",
            "2036  ⊞    Green         CY822025         43561615           A 210 501 0615   \n",
            "2037  ⊞    Green         CY822025         43561615           A 169 540 1617   \n",
            "2045  ⊞    Green         CY822025         43561615           A 642 180 0009   \n",
            "2046  ⊞    Green   C22   CY822025         43561615           A 247 900 9703   \n",
            "2047  ⊞    Green         CY822025         43561615           A 654 092 0000   \n",
            "2049  ⊞    Green         CY822025         43561615           A 205 866 0000   \n",
            "2050  ⊞    Green   C53   CY822025         43561615           A 001 998 7301   \n",
            "2051  ⊞    Green         CY822025         43561615           A 000 990 1807   \n",
            "2052  ⊞    Green         CY822025         43561615           A 205 330 6510   \n",
            "2053  ⊞    Green         CY822025         43561615           A 205 330 6610   \n",
            "2054  ⊞    Green         CY822025         43561615           A 205 330 6510   \n",
            "2055  ⊞    Green         CY822025         43561615           A 205 330 6610   \n",
            "2848  ⊞    Green         CY822025         43281568           A 223 835 2300   \n",
            "3756  ⊞    Green         CY822025         43041533           A 270 200 0200   \n",
            "3765  ⊞    Green         CY822025         43041533           A 222 899 0600   \n",
            "3773  ⊞    Green         CY822025         43041533           A 447 880 1114   \n",
            "3774  ⊞    Green         CY822025         43041533           A 447 880 1214   \n",
            "4527  ⊞    Green   C21   CY822025         42871473  A 222 905 5111     9051   \n",
            "4528  ⊞    Green   C21   CY822025         42871473  A 222 905 0309     9051   \n",
            "4529  ⊞    Green   C21   CY822025         42871473  A 213 905 4803     9051   \n",
            "\n",
            "     Designation of part no. Ordered Designation of part no. Confirmed  \\\n",
            "5                            BATTERY                           BATTERY   \n",
            "122              PARTS KIT, BRAKEPAD               PARTS KIT, BRAKEPAD   \n",
            "123              PARTS KIT, BRAKEPAD               PARTS KIT, BRAKEPAD   \n",
            "124               AIR FILTER ELEMENT                AIR FILTER ELEMENT   \n",
            "133                       SCREW PLUG                        SCREW PLUG   \n",
            "147             BRAKEPAD WEAR SENSOR              BRAKEPAD WEAR SENSOR   \n",
            "155                OPERATOR'S MANUAL                 OPERATOR'S MANUAL   \n",
            "156                OPERATOR'S MANUAL                 OPERATOR'S MANUAL   \n",
            "157                        TRUNK TUB                         TRUNK TUB   \n",
            "158                        FLOOR MAT                         FLOOR MAT   \n",
            "159                        FLOOR MAT                         FLOOR MAT   \n",
            "162             PARTS KIT, FLOOR MAT              PARTS KIT, FLOOR MAT   \n",
            "163                KEY HOUSING COVER                 KEY HOUSING COVER   \n",
            "164          MOLDING, STEERING WHEEL           MOLDING, STEERING WHEEL   \n",
            "165                     SEALING RING                      SEALING RING   \n",
            "166               AIR FILTER ELEMENT                AIR FILTER ELEMENT   \n",
            "167        PARTS KIT, FILTER ELEMENT         PARTS KIT, FILTER ELEMENT   \n",
            "168        PARTS KIT, FILTER ELEMENT         PARTS KIT, FILTER ELEMENT   \n",
            "169               AIR FILTER ELEMENT                AIR FILTER ELEMENT   \n",
            "170               AIR FILTER ELEMENT                AIR FILTER ELEMENT   \n",
            "171                     SEALING RING                      SEALING RING   \n",
            "172             BRAKEPAD WEAR SENSOR              BRAKEPAD WEAR SENSOR   \n",
            "173             BRAKEPAD WEAR SENSOR              BRAKEPAD WEAR SENSOR   \n",
            "174             BRAKEPAD WEAR SENSOR              BRAKEPAD WEAR SENSOR   \n",
            "1264               BEADED METAL SEAL                 BEADED METAL SEAL   \n",
            "1469                      BRAKE DISK                        BRAKE DISK   \n",
            "1470                      BRAKE DISK                        BRAKE DISK   \n",
            "1478              AIR FILTER ELEMENT                AIR FILTER ELEMENT   \n",
            "1479              AIR FILTER ELEMENT                AIR FILTER ELEMENT   \n",
            "1480       PARTS KIT, FILTER ELEMENT         PARTS KIT, FILTER ELEMENT   \n",
            "1481                     FUEL FILTER                       FUEL FILTER   \n",
            "1482                    SWITCH BLOCK                      SWITCH BLOCK   \n",
            "1694                    SEALING RING                      SEALING RING   \n",
            "1700                 SPRING LOCK NUT                   SPRING LOCK NUT   \n",
            "1701              AIR FILTER ELEMENT                AIR FILTER ELEMENT   \n",
            "1900                    BATTERY PACK                      BATTERY PACK   \n",
            "2033                    SWITCH BLOCK                      SWITCH BLOCK   \n",
            "2034                     VENTILATION                       VENTILATION   \n",
            "2035                          O-RING                            O-RING   \n",
            "2036                     CLOSING CAP                       CLOSING CAP   \n",
            "2037            BRAKEPAD WEAR SENSOR              BRAKEPAD WEAR SENSOR   \n",
            "2045       PARTS KIT, FILTER ELEMENT         PARTS KIT, FILTER ELEMENT   \n",
            "2046                    CONTROL UNIT                      CONTROL UNIT   \n",
            "2047             FUEL FILTER ELEMENT               FUEL FILTER ELEMENT   \n",
            "2049                CENTRIFUGAL PUMP                  CENTRIFUGAL PUMP   \n",
            "2050                  FORMED GROMMET                    FORMED GROMMET   \n",
            "2051          SPHERICAL COLLAR SCREW            SPHERICAL COLLAR SCREW   \n",
            "2052                     SPRING LINK                       SPRING LINK   \n",
            "2053                     SPRING LINK                       SPRING LINK   \n",
            "2054                     SPRING LINK                       SPRING LINK   \n",
            "2055                     SPRING LINK                       SPRING LINK   \n",
            "2848                     DUST FILTER                       DUST FILTER   \n",
            "3756        COOLANT INLET CONNECTION          COOLANT INLET CONNECTION   \n",
            "3765                          FLACON                            FLACON   \n",
            "3773                          HOLDER                            HOLDER   \n",
            "3774                          HOLDER                            HOLDER   \n",
            "4527                    SWITCH BLOCK                      SWITCH BLOCK   \n",
            "4528                    SWITCH BLOCK                      SWITCH BLOCK   \n",
            "4529                    SWITCH BLOCK                      SWITCH BLOCK   \n",
            "\n",
            "                Ord. date Items status  ...  M code Shelf life  \\\n",
            "5     06/01/2025 06:48 pm    Completed  ...  1PV988       15.0   \n",
            "122   06/01/2025 05:55 pm    Completed  ...  2TV415        NaN   \n",
            "123   06/01/2025 05:55 pm    Completed  ...  2TV415        NaN   \n",
            "124   06/01/2025 05:55 pm    Completed  ...  2TW130        NaN   \n",
            "133   06/01/2025 05:55 pm    Completed  ...  1PV980        NaN   \n",
            "147   06/01/2025 05:55 pm    Completed  ...  2TV547        NaN   \n",
            "155   06/01/2025 05:55 pm    Completed  ...  1POL92        NaN   \n",
            "156   06/01/2025 05:55 pm         Open  ...  1POL92        NaN   \n",
            "157   06/01/2025 05:55 pm         Open  ...  1PZ732        NaN   \n",
            "158   06/01/2025 05:55 pm    Completed  ...  1PZ741        NaN   \n",
            "159   06/01/2025 05:55 pm         Open  ...  1PZ741        NaN   \n",
            "162   06/01/2025 05:55 pm    Completed  ...  1GV676        NaN   \n",
            "163   06/01/2025 05:55 pm    Completed  ...  1PV649        NaN   \n",
            "164   06/01/2025 05:55 pm         Open  ...  1PV322        NaN   \n",
            "165   06/01/2025 05:55 pm    Completed  ...  1PV986        NaN   \n",
            "166   06/01/2025 05:55 pm    Completed  ...  2TW130        NaN   \n",
            "167   06/01/2025 05:55 pm    Completed  ...  1PW125        NaN   \n",
            "168   06/01/2025 05:55 pm    Completed  ...  1PW125        NaN   \n",
            "169   06/01/2025 05:55 pm    Completed  ...  1PW130        NaN   \n",
            "170   06/01/2025 05:55 pm    Completed  ...  1PW130        NaN   \n",
            "171   06/01/2025 05:55 pm    Completed  ...  1PV986        NaN   \n",
            "172   06/01/2025 05:55 pm    Completed  ...  1PV413        NaN   \n",
            "173   06/01/2025 05:55 pm    Completed  ...  1PV413        NaN   \n",
            "174   06/01/2025 05:55 pm    Completed  ...  1PV413        NaN   \n",
            "1264  27/11/2024 07:01 pm    Completed  ...  1PV105        NaN   \n",
            "1469  19/11/2024 09:49 am    Completed  ...  2TV425        NaN   \n",
            "1470  19/11/2024 09:49 am    Completed  ...  2TV425        NaN   \n",
            "1478  19/11/2024 09:49 am    Completed  ...  1PW130        NaN   \n",
            "1479  19/11/2024 09:49 am    Completed  ...  1PW130        NaN   \n",
            "1480  19/11/2024 09:49 am    Completed  ...  1PW125        NaN   \n",
            "1481  19/11/2024 09:49 am    Completed  ...  1PW135        NaN   \n",
            "1482  19/11/2024 09:49 am    Completed  ...  1PV543        NaN   \n",
            "1694  12/11/2024 05:56 pm    Completed  ...  1PV986        NaN   \n",
            "1700  12/11/2024 05:56 pm         Open  ...  1PV981        NaN   \n",
            "1701  12/11/2024 05:56 pm    Completed  ...  1PW130        NaN   \n",
            "1900  01/11/2024 06:24 pm    Completed  ...  1OX000      120.0   \n",
            "2033  01/11/2024 05:30 pm    Completed  ...  1PV543        NaN   \n",
            "2034  01/11/2024 05:30 pm    Completed  ...  1PV517        NaN   \n",
            "2035  01/11/2024 05:30 pm    Completed  ...  1PV986        NaN   \n",
            "2036  01/11/2024 05:30 pm    Completed  ...  1PV176        NaN   \n",
            "2037  01/11/2024 05:30 pm    Completed  ...  1PV413        NaN   \n",
            "2045  01/11/2024 05:30 pm    Completed  ...  1PW125        NaN   \n",
            "2046  01/11/2024 05:30 pm    Completed  ...  1PV537        NaN   \n",
            "2047  01/11/2024 05:30 pm    Completed  ...  1PW135        NaN   \n",
            "2049  01/11/2024 05:30 pm    Completed  ...  1PV566        NaN   \n",
            "2050  01/11/2024 05:30 pm    Completed  ...  2TV986        NaN   \n",
            "2051  01/11/2024 05:30 pm    Completed  ...  1PV980        NaN   \n",
            "2052  01/11/2024 05:30 pm    Completed  ...  1PV032        NaN   \n",
            "2053  01/11/2024 05:30 pm    Completed  ...  1PV032        NaN   \n",
            "2054  01/11/2024 05:30 pm    Completed  ...  1PV032        NaN   \n",
            "2055  01/11/2024 05:30 pm    Completed  ...  1PV032        NaN   \n",
            "2848  03/10/2024 05:48 pm    Completed  ...  1PW660        NaN   \n",
            "3756  12/09/2024 06:21 pm    Completed  ...  1PV141        NaN   \n",
            "3765  12/09/2024 06:21 pm    Completed  ...  1PZ733        NaN   \n",
            "3773  12/09/2024 06:21 pm    Completed  ...  2TU622        NaN   \n",
            "3774  12/09/2024 06:21 pm    Completed  ...  2TU622        NaN   \n",
            "4527  13/08/2024 12:48 pm    Completed  ...  1PV546        NaN   \n",
            "4528  13/08/2024 12:48 pm    Completed  ...  1PV546        NaN   \n",
            "4529  13/08/2024 12:48 pm    Completed  ...  1PV543        NaN   \n",
            "\n",
            "     Return excluded DRT ID Request no. Hub ind. CON Costing code  \\\n",
            "5                 X     NaN         NaN          NaN          NaN   \n",
            "122                     NaN         NaN       X  NaN          NaN   \n",
            "123                     NaN         NaN       X  NaN          NaN   \n",
            "124                     NaN         NaN       X  NaN          NaN   \n",
            "133                     NaN         NaN       X  NaN          NaN   \n",
            "147                     NaN         NaN       X  NaN          NaN   \n",
            "155               X     NaN         NaN       X  NaN          NaN   \n",
            "156               X     NaN         NaN       X  NaN          NaN   \n",
            "157                     NaN         NaN       X  NaN          NaN   \n",
            "158                     NaN         NaN       X  NaN          NaN   \n",
            "159                     NaN         NaN       X  NaN          NaN   \n",
            "162                     NaN         NaN       X  NaN          NaN   \n",
            "163                     NaN         NaN       X  NaN          NaN   \n",
            "164                     NaN         NaN       X  NaN          NaN   \n",
            "165                     NaN         NaN       X  NaN          NaN   \n",
            "166                     NaN         NaN       X  NaN          NaN   \n",
            "167                     NaN         NaN       X  NaN          NaN   \n",
            "168                     NaN         NaN       X  NaN          NaN   \n",
            "169                     NaN         NaN       X  NaN          NaN   \n",
            "170                     NaN         NaN       X  NaN          NaN   \n",
            "171                     NaN         NaN       X  NaN          NaN   \n",
            "172                     NaN         NaN       X  NaN          NaN   \n",
            "173                     NaN         NaN       X  NaN          NaN   \n",
            "174                     NaN         NaN       X  NaN          NaN   \n",
            "1264                    NaN         NaN       X  NaN          NaN   \n",
            "1469                    NaN         NaN       X  NaN          NaN   \n",
            "1470                    NaN         NaN       X  NaN          NaN   \n",
            "1478                    NaN         NaN       X  NaN          NaN   \n",
            "1479                    NaN         NaN       X  NaN          NaN   \n",
            "1480                    NaN         NaN       X  NaN          NaN   \n",
            "1481                    NaN         NaN       X  NaN          NaN   \n",
            "1482                    NaN         NaN       X  NaN          NaN   \n",
            "1694                    NaN         NaN       X  NaN          NaN   \n",
            "1700                    NaN         NaN       X  NaN          NaN   \n",
            "1701                    NaN         NaN       X  NaN          NaN   \n",
            "1900              X     NaN         NaN          NaN          NaN   \n",
            "2033                    NaN         NaN       X  NaN          NaN   \n",
            "2034                    NaN         NaN       X  NaN          NaN   \n",
            "2035                    NaN         NaN       X  NaN          NaN   \n",
            "2036                    NaN         NaN       X  NaN          NaN   \n",
            "2037                    NaN         NaN       X  NaN          NaN   \n",
            "2045                    NaN         NaN       X  NaN          NaN   \n",
            "2046                    NaN         NaN       X  NaN          NaN   \n",
            "2047                    NaN         NaN       X  NaN          NaN   \n",
            "2049                    NaN         NaN       X  NaN          NaN   \n",
            "2050                    NaN         NaN       X  NaN          NaN   \n",
            "2051                    NaN         NaN       X  NaN          NaN   \n",
            "2052                    NaN         NaN       X  NaN          NaN   \n",
            "2053                    NaN         NaN       X  NaN          NaN   \n",
            "2054                    NaN         NaN       X  NaN          NaN   \n",
            "2055                    NaN         NaN       X  NaN          NaN   \n",
            "2848                    NaN         NaN       X  NaN          NaN   \n",
            "3756                    NaN         NaN       X  NaN          NaN   \n",
            "3765              X     NaN         NaN       X  NaN          NaN   \n",
            "3773                    NaN         NaN       X  NaN          NaN   \n",
            "3774                    NaN         NaN       X  NaN          NaN   \n",
            "4527                    NaN         NaN       X  NaN          NaN   \n",
            "4528                    NaN         NaN       X  NaN          NaN   \n",
            "4529                    NaN         NaN       X  NaN          NaN   \n",
            "\n",
            "     Situation report Cleaned Customer info  \n",
            "5                 NaN                 GIRNE  \n",
            "122               NaN                 GİRNE  \n",
            "123               NaN                 GIRNE  \n",
            "124               NaN                 GIRNE  \n",
            "133               NaN                 GIRNE  \n",
            "147               NaN                 GIRNE  \n",
            "155               NaN                 GIRNE  \n",
            "156               NaN                 GIRNE  \n",
            "157               NaN                 GIRNE  \n",
            "158               NaN                 GIRNE  \n",
            "159               NaN                 GIRNE  \n",
            "162               NaN                 GİRNE  \n",
            "163               NaN                 GİRNE  \n",
            "164               NaN                 GİRNE  \n",
            "165               NaN                 GİRNE  \n",
            "166               NaN                 GİRNE  \n",
            "167               NaN                 GİRNE  \n",
            "168               NaN                 GIRNE  \n",
            "169               NaN                 GIRNE  \n",
            "170               NaN                 GIRNE  \n",
            "171               NaN                 GIRNE  \n",
            "172               NaN                 GIRNE  \n",
            "173               NaN                 GIRNE  \n",
            "174               NaN                 GIRNE  \n",
            "1264              NaN                 GIRNE  \n",
            "1469              NaN                 GIRNE  \n",
            "1470              NaN                 GIRNE  \n",
            "1478              NaN                 GIRNE  \n",
            "1479              NaN                 GIRNE  \n",
            "1480              NaN                 GIRNE  \n",
            "1481              NaN                 GIRNE  \n",
            "1482              NaN                 GIRNE  \n",
            "1694              NaN                 GIRNE  \n",
            "1700              NaN                 GIRNE  \n",
            "1701              NaN                 GIRNE  \n",
            "1900              NaN                 GIRNE  \n",
            "2033              NaN                 GIRNE  \n",
            "2034              NaN                 GIRNE  \n",
            "2035              NaN                 GIRNE  \n",
            "2036              NaN                 GIRNE  \n",
            "2037              NaN                 GIRNE  \n",
            "2045              NaN                 GIRNE  \n",
            "2046              NaN                 GIRNE  \n",
            "2047              NaN                 GIRNE  \n",
            "2049              NaN                 GIRNE  \n",
            "2050              NaN                 GIRNE  \n",
            "2051              NaN                 GIRNE  \n",
            "2052              NaN                 GIRNE  \n",
            "2053              NaN                 GIRNE  \n",
            "2054              NaN                 GIRNE  \n",
            "2055              NaN                 GIRNE  \n",
            "2848              NaN                 GIRNE  \n",
            "3756              NaN                 GIRNE  \n",
            "3765              NaN                 GIRNE  \n",
            "3773              NaN                 GIRNE  \n",
            "3774              NaN                 GIRNE  \n",
            "4527              NaN                 GIRNE  \n",
            "4528              NaN                 GIRNE  \n",
            "4529              NaN                 GIRNE  \n",
            "\n",
            "[59 rows x 63 columns]\n",
            "Merged data has been saved to /content/cgniv_StarOrderplus_Order_items.xlsx\n",
            "Number of rows in the original df2 file: 3147\n",
            "Number of rows in the result file: 3147\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-6d16b977b4dd>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;31m# Search for tracking numbers in emails\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m \u001b[0mtracking_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msearch_emails_for_tracking_numbers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdn_numbers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[0;31m# Update the existing entries with the tracking numbers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-6d16b977b4dd>\u001b[0m in \u001b[0;36msearch_emails_for_tracking_numbers\u001b[0;34m(dn_numbers)\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0memail_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0memail_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0memail_ids\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmail\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memail_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'(RFC822)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'OK'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Failed to fetch email with ID {email_id}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/imaplib.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, message_set, message_parts)\u001b[0m\n\u001b[1;32m    546\u001b[0m         \"\"\"\n\u001b[1;32m    547\u001b[0m         \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'FETCH'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 548\u001b[0;31m         \u001b[0mtyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_simple_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage_parts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    549\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_untagged_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/imaplib.py\u001b[0m in \u001b[0;36m_simple_command\u001b[0;34m(self, name, *args)\u001b[0m\n\u001b[1;32m   1228\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_simple_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1230\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_command_complete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/imaplib.py\u001b[0m in \u001b[0;36m_command_complete\u001b[0;34m(self, name, tag)\u001b[0m\n\u001b[1;32m   1045\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_bye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1047\u001b[0;31m             \u001b[0mtyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tagged_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_bye\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1048\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabort\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1049\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'command: %s => %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/imaplib.py\u001b[0m in \u001b[0;36m_get_tagged_response\u001b[0;34m(self, tag, expect_bye)\u001b[0m\n\u001b[1;32m   1171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1173\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1174\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabort\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0m__debug__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/imaplib.py\u001b[0m in \u001b[0;36m_get_response\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1073\u001b[0m         \u001b[0;31m# otherwise first response line received.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1074\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1075\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1076\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1077\u001b[0m         \u001b[0;31m# Command completion response?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/imaplib.py\u001b[0m in \u001b[0;36m_get_line\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1181\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'socket error: EOF'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/imaplib.py\u001b[0m in \u001b[0;36mreadline\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m         \u001b[0;34m\"\"\"Read line from remote.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"got more than %d bytes\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    716\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 718\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    719\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1312\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1313\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1314\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1315\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1164\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1165\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1166\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1167\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***code for new star order site 16_01_25  trıal stıll ***"
      ],
      "metadata": {
        "id": "EUFVFqPrKTNb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from datetime import timedelta\n",
        "import imaplib\n",
        "import email\n",
        "from email.header import decode_header\n",
        "import chardet\n",
        "import re\n",
        "\n",
        "# Email account credentials\n",
        "username = 'kombosawb@gmail.com'\n",
        "password = 'kyka ypey hfar rjvg'  # Use the App Password here\n",
        "\n",
        "# File paths for input Excel files\n",
        "file_path = '/content/updated_Order_items (38).xlsx'\n",
        "file_path1 = '/content/updated_Mercedes_Yedek_Parça_Sipariş_2024 (38).xlsx'\n",
        "file_path2 = '/content/niv_StarOrderplus_Order_items_new.xlsx'\n",
        "input_file = '/content/cgniv_StarOrderplus_Order_items.xlsx'\n",
        "\n",
        "# File path for the output Excel file\n",
        "output_file = '/content/vaugzcstcketrd_expstckentryd_status_trcklnk_trckno.xlsx'\n",
        "exdf1 = '/content/df1_unique.xlsx'\n",
        "exdf2 = '/content/df2.xlsx'\n",
        "\n",
        "# Load and clean the first Excel file\n",
        "df = pd.read_excel(file_path)\n",
        "\n",
        "# Create 'Cleaned Customer info' column by removing spaces, unwanted characters, and suffixes like '-i', '/G', etc.\n",
        "if 'Customer info' in df.columns:\n",
        "    # Updated regex to handle various suffixes including special characters\n",
        "    df['Cleaned Customer info'] = df['Customer info'].astype(str).str.replace(' ', '').str.upper().str.replace(r'[-/][A-ZİÝIi]+$', '', regex=True)\n",
        "else:\n",
        "    print(\"The column 'Customer info' was not found in the file.\")\n",
        "    df['Cleaned Customer info'] = df['Customer info']\n",
        "\n",
        "# Remove rows with unwanted 'Customer info' entries\n",
        "df_cleaned = df[~df['Cleaned Customer info'].str.lower().str.startswith(('stok', 'stpk', 'minarelikoy', 'mýna', 'stock', 'raf')) &\n",
        "                ~df['Cleaned Customer info'].str.startswith(('RAF', 'STOCKMT'))]\n",
        "\n",
        "# Save the cleaned DataFrame to a new Excel file\n",
        "df_cleaned.to_excel(file_path2, index=False)\n",
        "\n",
        "# Function to get customer info details\n",
        "def get_customer_info_details():\n",
        "    customer_info_input = input(\"Enter the customer info: \").strip()\n",
        "    if 'Cleaned Customer info' in df_cleaned.columns:\n",
        "        part_details = df_cleaned[df_cleaned['Cleaned Customer info'].astype(str).str.contains(customer_info_input, case=False, na=False)]\n",
        "    else:\n",
        "        print(\"The column 'Cleaned Customer info' was not found in the cleaned file.\")\n",
        "        return\n",
        "\n",
        "    if not part_details.empty:\n",
        "        print(\"Customer info Details:\")\n",
        "        print(part_details)\n",
        "    else:\n",
        "        print(\"No details found for the entered customer info.\")\n",
        "\n",
        "# Run the function\n",
        "get_customer_info_details()\n",
        "\n",
        "# Load the cleaned DataFrame and other Excel files\n",
        "df_cleaned = pd.read_excel(file_path2)\n",
        "df1 = pd.read_excel(file_path1)\n",
        "df2 = pd.read_excel(file_path2)\n",
        "\n",
        "# Check for required columns in df1 and df2\n",
        "required_columns = {'Customer info', 'Part number'}\n",
        "missing_columns_df1 = required_columns - set(df1.columns)\n",
        "missing_columns_df2 = required_columns - set(df2.columns)\n",
        "\n",
        "if missing_columns_df1:\n",
        "    print(f\"The following required columns are missing in the first file: {missing_columns_df1}\")\n",
        "if missing_columns_df2:\n",
        "    print(f\"The following required columns are missing in the second file: {missing_columns_df2}\")\n",
        "\n",
        "if not missing_columns_df1 and not missing_columns_df2:\n",
        "    # Clean 'Part number' columns in df1 and df2\n",
        "    df1['Cleaned Part number'] = df1['Part number'].astype(str).str.replace(' ', '').str.upper().str[:10]\n",
        "    df2['Cleaned Part number'] = df2['Part number'].astype(str).str.replace(' ', '').str.upper().str[:10]\n",
        "\n",
        "    # Clean 'Customer info' columns in df1\n",
        "    df1['Cleaned Customer info'] = df1['Customer info'].astype(str).str.replace(' ', '').str.upper().str.replace(r'[-/][A-ZİÝIi]+$', '', regex=True)\n",
        "    df1_unique = df1.drop_duplicates(subset=['Cleaned Customer info', 'Cleaned Part number'])\n",
        "\n",
        "    # Save df1_unique for verification\n",
        "    df1_unique.to_excel(exdf1, index=False)\n",
        "\n",
        "    # Clean 'Customer info' columns in df2\n",
        "    df2['Cleaned Customer info'] = df2['Customer info'].astype(str).str.replace(' ', '').str.upper().str.replace(r'[-/][A-ZİÝIi]+$', '', regex=True)\n",
        "\n",
        "    # Merge 'StockEntryDate' from df1_unique into df2 based on cleaned columns\n",
        "    merged_df = pd.merge(df2, df1_unique[['Cleaned Customer info', 'Cleaned Part number', 'StockEntryDate']],\n",
        "                         on=['Cleaned Customer info', 'Cleaned Part number'], how='left')\n",
        "\n",
        "    # Save the resulting DataFrame\n",
        "    merged_df.to_excel(input_file, index=False)\n",
        "    print(f\"Merged data has been saved to {input_file}\")\n",
        "    print(f\"Number of rows in the original df2 file: {len(df2)}\")\n",
        "    print(f\"Number of rows in the result file: {len(merged_df)}\")\n",
        "\n",
        "else:\n",
        "    print(\"One or both required columns 'Customer info' or 'Part number' were not found in the provided files.\")\n",
        "\n",
        "# Load the updated DataFrame\n",
        "df = pd.read_excel(input_file)\n",
        "\n",
        "# Connect to the email server\n",
        "mail = imaplib.IMAP4_SSL('imap.gmail.com')\n",
        "\n",
        "def fetch_stt_number(body):\n",
        "    stt_number_match = re.search(r'STT Number[:\\.\\s]+(\\d+)', body)\n",
        "    return stt_number_match.group(1) if stt_number_match else 'Not Found'\n",
        "\n",
        "def search_emails_for_tracking_numbers(dn_numbers):\n",
        "    tracking_dict = {dn_number: 'Not Found' for dn_number in dn_numbers}\n",
        "    mail.login(username, password)\n",
        "    mail.select('inbox')\n",
        "\n",
        "    result, data = mail.search(None, 'ALL')\n",
        "    if result != 'OK':\n",
        "        print(\"Failed to search for emails.\")\n",
        "        return tracking_dict\n",
        "\n",
        "    email_ids = data[0].split()\n",
        "    for email_id in email_ids:\n",
        "        result, msg_data = mail.fetch(email_id, '(RFC822)')\n",
        "        if result != 'OK':\n",
        "            print(f\"Failed to fetch email with ID {email_id}\")\n",
        "            continue\n",
        "\n",
        "        raw_email = msg_data[0][1]\n",
        "        msg = email.message_from_bytes(raw_email)\n",
        "\n",
        "        # Decode email body\n",
        "        body = \"\"\n",
        "        if msg.is_multipart():\n",
        "            for part in msg.walk():\n",
        "                if part.get_content_type() == 'text/plain':\n",
        "                    payload = part.get_payload(decode=True)\n",
        "                    detected_encoding = chardet.detect(payload)['encoding']\n",
        "                    body = payload.decode(detected_encoding or 'utf-8', errors='replace')\n",
        "                    break\n",
        "        else:\n",
        "            payload = msg.get_payload(decode=True)\n",
        "            detected_encoding = chardet.detect(payload)['encoding']\n",
        "            body = payload.decode(detected_encoding or 'utf-8', errors='replace')\n",
        "\n",
        "        # Check for each DN number in the body\n",
        "        for dn_number in dn_numbers:\n",
        "            if dn_number in body:\n",
        "                tracking_dict[dn_number] = fetch_stt_number(body)\n",
        "\n",
        "    return tracking_dict\n",
        "\n",
        "# Define the function to compute the expected stock entry date\n",
        "def calculate_expected_stock_entry_date(row):\n",
        "    try:\n",
        "        inv_date_dispatch_date = pd.to_datetime(row['Inv. date dispatch date'], dayfirst=True, errors='coerce')\n",
        "        if pd.notnull(inv_date_dispatch_date):\n",
        "            conf_dd_confirmed_dispatch_date = pd.to_datetime(row['Conf. DD confirmed dispatch date'], dayfirst=True, errors='coerce')\n",
        "            expected_dd_expected_to_be_dispatched = pd.to_datetime(row['Expected DD expecte to be dispatched'], dayfirst=True, errors='coerce')\n",
        "\n",
        "            if row['Dist. ch.'] == 'af VOR direct':\n",
        "                days_to_add = 10\n",
        "            elif row['Dist. ch.'] == 'VOR route':\n",
        "                days_to_add = 21\n",
        "            else:\n",
        "                days_to_add = 10\n",
        "\n",
        "            return inv_date_dispatch_date + timedelta(days=days_to_add)\n",
        "        return pd.NaT\n",
        "    except KeyError as e:\n",
        "        print(f\"Column not found: {e}\")\n",
        "        return pd.NaT\n",
        "\n",
        "# Apply the function to each row to create the new column\n",
        "df['expectedstockentrydate'] = df.apply(calculate_expected_stock_entry_date, axis=1)\n",
        "\n",
        "# Define the function to compute the status\n",
        "def determine_status(row):\n",
        "    inv_date_dispatch_date = pd.to_datetime(row.get('Inv. date dispatch date', None), dayfirst=True, errors='coerce')\n",
        "    conf_dd_confirmed_dispatch_date = pd.to_datetime(row.get('Conf. DD confirmed dispatch date', None), dayfirst=True, errors='coerce')\n",
        "    expected_dd_expected_to_be_dispatched = pd.to_datetime(row.get('Expected DD expecte to be dispatched', None), dayfirst=True, errors='coerce')\n",
        "\n",
        "    if pd.notnull(inv_date_dispatch_date):\n",
        "        return f'invoice dispatch date on {inv_date_dispatch_date.strftime(\"%d/%m/%Y\")}'\n",
        "    elif pd.notnull(conf_dd_confirmed_dispatch_date):\n",
        "        return f'confirmed dispatch date on {conf_dd_confirmed_dispatch_date.strftime(\"%d/%m/%Y\")}'\n",
        "    elif pd.notnull(expected_dd_expected_to_be_dispatched):\n",
        "        return 'backorder'\n",
        "    else:\n",
        "        return 'backorder'\n",
        "\n",
        "# Apply the function to create the new status column\n",
        "df['status'] = df.apply(determine_status, axis=1)\n",
        "\n",
        "# Update status for rejected items\n",
        "df.loc[(df['Items status'] == 'Rejected') & (df['status'] == 'backorder'), 'status'] = 'Rejected'\n",
        "\n",
        "# Create the list_of_backorders column for searching\n",
        "def determine_backorders(row):\n",
        "    inv_date_dispatch_date = pd.to_datetime(row.get('Inv. date dispatch date', None), dayfirst=True, errors='coerce')\n",
        "    conf_dd_confirmed_dispatch_date = pd.to_datetime(row.get('Conf. DD confirmed dispatch date', None), dayfirst=True, errors='coerce')\n",
        "    expected_dd_expected_to_be_dispatched = pd.to_datetime(row.get('Expected DD expecte to be dispatched', None), dayfirst=True, errors='coerce')\n",
        "\n",
        "    if pd.isnull(inv_date_dispatch_date) and pd.isnull(conf_dd_confirmed_dispatch_date) and (pd.notnull(expected_dd_expected_to_be_dispatched) or pd.isnull(expected_dd_expected_to_be_dispatched)):\n",
        "        return 'backorders'\n",
        "    else:\n",
        "        return ''\n",
        "\n",
        "# Apply the function to create the new list_of_backorders column\n",
        "df['list_of_backorders'] = df.apply(determine_backorders, axis=1)\n",
        "\n",
        "# Filter out 'Rejected' items when searching for backorders\n",
        "filtered_df = df[(df['status'] == 'backorder') & (df['list_of_backorders'] == 'backorders')]\n",
        "\n",
        "# Get the list of DN numbers from the DataFrame\n",
        "dn_numbers = df['DN no.'].dropna().astype(str).tolist()\n",
        "\n",
        "# Search for tracking numbers in emails\n",
        "tracking_dict = search_emails_for_tracking_numbers(dn_numbers)\n",
        "\n",
        "# Update the existing entries with the tracking numbers\n",
        "df['Tracking No'] = df['DN no.'].map(tracking_dict)\n",
        "\n",
        "# Create the tracking details column\n",
        "df['tracking_details'] = df['Tracking No'].apply(lambda x: f'https://dbschenker.com/app/tracking-public/?refNumber={x}' if x != 'Not Found' else '')\n",
        "\n",
        "# Set tracking_details to blank if the value contains 'nan'\n",
        "df['tracking_details'] = df['tracking_details'].apply(lambda x: '' if 'nan' in x else x)\n",
        "\n",
        "# Set StockEntryDate to NaT where status is 'backorder' or 'Rejected'\n",
        "df.loc[df['status'].isin(['backorder', 'Rejected']), 'StockEntryDate'] = pd.NaT\n",
        "\n",
        "# Save results to a new Excel file\n",
        "df.to_excel(output_file, index=False)\n",
        "print(f\"Updated file saved to {output_file}\")\n",
        "\n",
        "# Close the connection and logout\n",
        "mail.close()\n",
        "mail.logout()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "MR_11wYIEHgh",
        "outputId": "08f9b85b-c9fc-4054-ee0b-9a206c805613"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the customer info: Girne\n",
            "Customer info Details:\n",
            "       ±     gATP  Code Cust. No.  Cust. order no.              Part number  \\\n",
            "5     ⊞   Yellow         CY822025         43931734          N 000000 004039   \n",
            "122   ⊞    Green         CY822025         43931734           A 447 420 6600   \n",
            "123   ⊞    Green         CY822025         43931734           A 447 420 6700   \n",
            "124   ⊞    Green         CY822025         43931734           A 654 094 1500   \n",
            "133   ⊞    Green         CY822025         43931734           A 002 990 2017   \n",
            "147   ⊞    Green         CY822025         43931734           A 906 540 1517   \n",
            "155   ⊞    Green         CY822025         43931734  A 247 584 3313     Z102   \n",
            "156   ⊞      Red         CY822025         43931734  A 206 584 6505     Z102   \n",
            "157   ⊞      Red         CY822025         43931734           A 243 814 0000   \n",
            "158   ⊞    Green         CY822025         43931734  A 177 680 8002     9G33   \n",
            "159   ⊞      Red         CY822025         43931734  A 247 680 0203     9G33   \n",
            "162   ⊞    Green         CY822025         43931734  A 465 680 1300     9051   \n",
            "163   ⊞    Green         CY822025         43931734           A 213 766 0600   \n",
            "164   ⊞      Red         CY822025         43931734  A 099 464 0013     9107   \n",
            "165   ⊞    Green         CY822025         43931734           A 622 017 0000   \n",
            "166   ⊞    Green         CY822025         43931734           A 654 094 1500   \n",
            "167   ⊞    Green         CY822025         43931734           A 271 180 0109   \n",
            "168   ⊞    Green         CY822025         43931734           A 271 180 0509   \n",
            "169   ⊞    Green         CY822025         43931734           A 271 094 0304   \n",
            "170   ⊞    Green         CY822025         43931734           A 271 094 0204   \n",
            "171   ⊞    Green         CY822025         43931734           A 607 997 0345   \n",
            "172   ⊞    Green         CY822025         43931734           A 231 905 0014   \n",
            "173   ⊞    Green         CY822025         43931734           A 164 540 1017   \n",
            "174   ⊞    Green         CY822025         43931734           A 169 540 1617   \n",
            "1264  ⊞    Green         CY822025         43681662           A 271 238 0380   \n",
            "1469  ⊞    Green         CY822025         43621640       A 447 421 0012  07   \n",
            "1470  ⊞    Green         CY822025         43621640       A 447 423 0012  07   \n",
            "1478  ⊞    Green   C21   CY822025         43621640           A 177 094 0000   \n",
            "1479  ⊞    Green   C21   CY822025         43621640           A 177 094 0100   \n",
            "1480  ⊞    Green         CY822025         43621640           A 278 180 0009   \n",
            "1481  ⊞    Green   C22   CY822025         43621640           A 642 090 5352   \n",
            "1482  ⊞    Green   C21   CY822025         43621640  A 205 905 6811     9051   \n",
            "1694  ⊞   Yellow         CY822025         43611630           A 094 990 8907   \n",
            "1700  ⊞      Red   C21   CY822025         43611630           A 004 994 1845   \n",
            "1701  ⊞    Green         CY822025         43611630           A 654 094 0004   \n",
            "1900  ⊞   Yellow         CY822025         43561612           A 000 828 0388   \n",
            "2033  ⊞    Green   C21   CY822025         43561615  A 205 905 6811     9051   \n",
            "2034  ⊞    Green   C21   CY822025         43561615           A 212 830 0242   \n",
            "2035  ⊞    Green         CY822025         43561615       A 000 997 3807  64   \n",
            "2036  ⊞    Green         CY822025         43561615           A 210 501 0615   \n",
            "2037  ⊞    Green         CY822025         43561615           A 169 540 1617   \n",
            "2045  ⊞    Green         CY822025         43561615           A 642 180 0009   \n",
            "2046  ⊞    Green   C22   CY822025         43561615           A 247 900 9703   \n",
            "2047  ⊞    Green         CY822025         43561615           A 654 092 0000   \n",
            "2049  ⊞    Green         CY822025         43561615           A 205 866 0000   \n",
            "2050  ⊞    Green   C53   CY822025         43561615           A 001 998 7301   \n",
            "2051  ⊞    Green         CY822025         43561615           A 000 990 1807   \n",
            "2052  ⊞    Green         CY822025         43561615           A 205 330 6510   \n",
            "2053  ⊞    Green         CY822025         43561615           A 205 330 6610   \n",
            "2054  ⊞    Green         CY822025         43561615           A 205 330 6510   \n",
            "2055  ⊞    Green         CY822025         43561615           A 205 330 6610   \n",
            "2848  ⊞    Green         CY822025         43281568           A 223 835 2300   \n",
            "3756  ⊞    Green         CY822025         43041533           A 270 200 0200   \n",
            "3765  ⊞    Green         CY822025         43041533           A 222 899 0600   \n",
            "3773  ⊞    Green         CY822025         43041533           A 447 880 1114   \n",
            "3774  ⊞    Green         CY822025         43041533           A 447 880 1214   \n",
            "4527  ⊞    Green   C21   CY822025         42871473  A 222 905 5111     9051   \n",
            "4528  ⊞    Green   C21   CY822025         42871473  A 222 905 0309     9051   \n",
            "4529  ⊞    Green   C21   CY822025         42871473  A 213 905 4803     9051   \n",
            "\n",
            "     Designation of part no. Ordered Designation of part no. Confirmed  \\\n",
            "5                            BATTERY                           BATTERY   \n",
            "122              PARTS KIT, BRAKEPAD               PARTS KIT, BRAKEPAD   \n",
            "123              PARTS KIT, BRAKEPAD               PARTS KIT, BRAKEPAD   \n",
            "124               AIR FILTER ELEMENT                AIR FILTER ELEMENT   \n",
            "133                       SCREW PLUG                        SCREW PLUG   \n",
            "147             BRAKEPAD WEAR SENSOR              BRAKEPAD WEAR SENSOR   \n",
            "155                OPERATOR'S MANUAL                 OPERATOR'S MANUAL   \n",
            "156                OPERATOR'S MANUAL                 OPERATOR'S MANUAL   \n",
            "157                        TRUNK TUB                         TRUNK TUB   \n",
            "158                        FLOOR MAT                         FLOOR MAT   \n",
            "159                        FLOOR MAT                         FLOOR MAT   \n",
            "162             PARTS KIT, FLOOR MAT              PARTS KIT, FLOOR MAT   \n",
            "163                KEY HOUSING COVER                 KEY HOUSING COVER   \n",
            "164          MOLDING, STEERING WHEEL           MOLDING, STEERING WHEEL   \n",
            "165                     SEALING RING                      SEALING RING   \n",
            "166               AIR FILTER ELEMENT                AIR FILTER ELEMENT   \n",
            "167        PARTS KIT, FILTER ELEMENT         PARTS KIT, FILTER ELEMENT   \n",
            "168        PARTS KIT, FILTER ELEMENT         PARTS KIT, FILTER ELEMENT   \n",
            "169               AIR FILTER ELEMENT                AIR FILTER ELEMENT   \n",
            "170               AIR FILTER ELEMENT                AIR FILTER ELEMENT   \n",
            "171                     SEALING RING                      SEALING RING   \n",
            "172             BRAKEPAD WEAR SENSOR              BRAKEPAD WEAR SENSOR   \n",
            "173             BRAKEPAD WEAR SENSOR              BRAKEPAD WEAR SENSOR   \n",
            "174             BRAKEPAD WEAR SENSOR              BRAKEPAD WEAR SENSOR   \n",
            "1264               BEADED METAL SEAL                 BEADED METAL SEAL   \n",
            "1469                      BRAKE DISK                        BRAKE DISK   \n",
            "1470                      BRAKE DISK                        BRAKE DISK   \n",
            "1478              AIR FILTER ELEMENT                AIR FILTER ELEMENT   \n",
            "1479              AIR FILTER ELEMENT                AIR FILTER ELEMENT   \n",
            "1480       PARTS KIT, FILTER ELEMENT         PARTS KIT, FILTER ELEMENT   \n",
            "1481                     FUEL FILTER                       FUEL FILTER   \n",
            "1482                    SWITCH BLOCK                      SWITCH BLOCK   \n",
            "1694                    SEALING RING                      SEALING RING   \n",
            "1700                 SPRING LOCK NUT                   SPRING LOCK NUT   \n",
            "1701              AIR FILTER ELEMENT                AIR FILTER ELEMENT   \n",
            "1900                    BATTERY PACK                      BATTERY PACK   \n",
            "2033                    SWITCH BLOCK                      SWITCH BLOCK   \n",
            "2034                     VENTILATION                       VENTILATION   \n",
            "2035                          O-RING                            O-RING   \n",
            "2036                     CLOSING CAP                       CLOSING CAP   \n",
            "2037            BRAKEPAD WEAR SENSOR              BRAKEPAD WEAR SENSOR   \n",
            "2045       PARTS KIT, FILTER ELEMENT         PARTS KIT, FILTER ELEMENT   \n",
            "2046                    CONTROL UNIT                      CONTROL UNIT   \n",
            "2047             FUEL FILTER ELEMENT               FUEL FILTER ELEMENT   \n",
            "2049                CENTRIFUGAL PUMP                  CENTRIFUGAL PUMP   \n",
            "2050                  FORMED GROMMET                    FORMED GROMMET   \n",
            "2051          SPHERICAL COLLAR SCREW            SPHERICAL COLLAR SCREW   \n",
            "2052                     SPRING LINK                       SPRING LINK   \n",
            "2053                     SPRING LINK                       SPRING LINK   \n",
            "2054                     SPRING LINK                       SPRING LINK   \n",
            "2055                     SPRING LINK                       SPRING LINK   \n",
            "2848                     DUST FILTER                       DUST FILTER   \n",
            "3756        COOLANT INLET CONNECTION          COOLANT INLET CONNECTION   \n",
            "3765                          FLACON                            FLACON   \n",
            "3773                          HOLDER                            HOLDER   \n",
            "3774                          HOLDER                            HOLDER   \n",
            "4527                    SWITCH BLOCK                      SWITCH BLOCK   \n",
            "4528                    SWITCH BLOCK                      SWITCH BLOCK   \n",
            "4529                    SWITCH BLOCK                      SWITCH BLOCK   \n",
            "\n",
            "                Ord. date Items status  ...  M code Shelf life  \\\n",
            "5     06/01/2025 06:48 pm    Completed  ...  1PV988       15.0   \n",
            "122   06/01/2025 05:55 pm    Completed  ...  2TV415        NaN   \n",
            "123   06/01/2025 05:55 pm    Completed  ...  2TV415        NaN   \n",
            "124   06/01/2025 05:55 pm    Completed  ...  2TW130        NaN   \n",
            "133   06/01/2025 05:55 pm    Completed  ...  1PV980        NaN   \n",
            "147   06/01/2025 05:55 pm    Completed  ...  2TV547        NaN   \n",
            "155   06/01/2025 05:55 pm    Completed  ...  1POL92        NaN   \n",
            "156   06/01/2025 05:55 pm         Open  ...  1POL92        NaN   \n",
            "157   06/01/2025 05:55 pm         Open  ...  1PZ732        NaN   \n",
            "158   06/01/2025 05:55 pm    Completed  ...  1PZ741        NaN   \n",
            "159   06/01/2025 05:55 pm         Open  ...  1PZ741        NaN   \n",
            "162   06/01/2025 05:55 pm    Completed  ...  1GV676        NaN   \n",
            "163   06/01/2025 05:55 pm    Completed  ...  1PV649        NaN   \n",
            "164   06/01/2025 05:55 pm         Open  ...  1PV322        NaN   \n",
            "165   06/01/2025 05:55 pm    Completed  ...  1PV986        NaN   \n",
            "166   06/01/2025 05:55 pm    Completed  ...  2TW130        NaN   \n",
            "167   06/01/2025 05:55 pm    Completed  ...  1PW125        NaN   \n",
            "168   06/01/2025 05:55 pm    Completed  ...  1PW125        NaN   \n",
            "169   06/01/2025 05:55 pm    Completed  ...  1PW130        NaN   \n",
            "170   06/01/2025 05:55 pm    Completed  ...  1PW130        NaN   \n",
            "171   06/01/2025 05:55 pm    Completed  ...  1PV986        NaN   \n",
            "172   06/01/2025 05:55 pm    Completed  ...  1PV413        NaN   \n",
            "173   06/01/2025 05:55 pm    Completed  ...  1PV413        NaN   \n",
            "174   06/01/2025 05:55 pm    Completed  ...  1PV413        NaN   \n",
            "1264  27/11/2024 07:01 pm    Completed  ...  1PV105        NaN   \n",
            "1469  19/11/2024 09:49 am    Completed  ...  2TV425        NaN   \n",
            "1470  19/11/2024 09:49 am    Completed  ...  2TV425        NaN   \n",
            "1478  19/11/2024 09:49 am    Completed  ...  1PW130        NaN   \n",
            "1479  19/11/2024 09:49 am    Completed  ...  1PW130        NaN   \n",
            "1480  19/11/2024 09:49 am    Completed  ...  1PW125        NaN   \n",
            "1481  19/11/2024 09:49 am    Completed  ...  1PW135        NaN   \n",
            "1482  19/11/2024 09:49 am    Completed  ...  1PV543        NaN   \n",
            "1694  12/11/2024 05:56 pm    Completed  ...  1PV986        NaN   \n",
            "1700  12/11/2024 05:56 pm         Open  ...  1PV981        NaN   \n",
            "1701  12/11/2024 05:56 pm    Completed  ...  1PW130        NaN   \n",
            "1900  01/11/2024 06:24 pm    Completed  ...  1OX000      120.0   \n",
            "2033  01/11/2024 05:30 pm    Completed  ...  1PV543        NaN   \n",
            "2034  01/11/2024 05:30 pm    Completed  ...  1PV517        NaN   \n",
            "2035  01/11/2024 05:30 pm    Completed  ...  1PV986        NaN   \n",
            "2036  01/11/2024 05:30 pm    Completed  ...  1PV176        NaN   \n",
            "2037  01/11/2024 05:30 pm    Completed  ...  1PV413        NaN   \n",
            "2045  01/11/2024 05:30 pm    Completed  ...  1PW125        NaN   \n",
            "2046  01/11/2024 05:30 pm    Completed  ...  1PV537        NaN   \n",
            "2047  01/11/2024 05:30 pm    Completed  ...  1PW135        NaN   \n",
            "2049  01/11/2024 05:30 pm    Completed  ...  1PV566        NaN   \n",
            "2050  01/11/2024 05:30 pm    Completed  ...  2TV986        NaN   \n",
            "2051  01/11/2024 05:30 pm    Completed  ...  1PV980        NaN   \n",
            "2052  01/11/2024 05:30 pm    Completed  ...  1PV032        NaN   \n",
            "2053  01/11/2024 05:30 pm    Completed  ...  1PV032        NaN   \n",
            "2054  01/11/2024 05:30 pm    Completed  ...  1PV032        NaN   \n",
            "2055  01/11/2024 05:30 pm    Completed  ...  1PV032        NaN   \n",
            "2848  03/10/2024 05:48 pm    Completed  ...  1PW660        NaN   \n",
            "3756  12/09/2024 06:21 pm    Completed  ...  1PV141        NaN   \n",
            "3765  12/09/2024 06:21 pm    Completed  ...  1PZ733        NaN   \n",
            "3773  12/09/2024 06:21 pm    Completed  ...  2TU622        NaN   \n",
            "3774  12/09/2024 06:21 pm    Completed  ...  2TU622        NaN   \n",
            "4527  13/08/2024 12:48 pm    Completed  ...  1PV546        NaN   \n",
            "4528  13/08/2024 12:48 pm    Completed  ...  1PV546        NaN   \n",
            "4529  13/08/2024 12:48 pm    Completed  ...  1PV543        NaN   \n",
            "\n",
            "     Return excluded DRT ID Request no. Hub ind. CON Costing code  \\\n",
            "5                 X     NaN         NaN          NaN          NaN   \n",
            "122                     NaN         NaN       X  NaN          NaN   \n",
            "123                     NaN         NaN       X  NaN          NaN   \n",
            "124                     NaN         NaN       X  NaN          NaN   \n",
            "133                     NaN         NaN       X  NaN          NaN   \n",
            "147                     NaN         NaN       X  NaN          NaN   \n",
            "155               X     NaN         NaN       X  NaN          NaN   \n",
            "156               X     NaN         NaN       X  NaN          NaN   \n",
            "157                     NaN         NaN       X  NaN          NaN   \n",
            "158                     NaN         NaN       X  NaN          NaN   \n",
            "159                     NaN         NaN       X  NaN          NaN   \n",
            "162                     NaN         NaN       X  NaN          NaN   \n",
            "163                     NaN         NaN       X  NaN          NaN   \n",
            "164                     NaN         NaN       X  NaN          NaN   \n",
            "165                     NaN         NaN       X  NaN          NaN   \n",
            "166                     NaN         NaN       X  NaN          NaN   \n",
            "167                     NaN         NaN       X  NaN          NaN   \n",
            "168                     NaN         NaN       X  NaN          NaN   \n",
            "169                     NaN         NaN       X  NaN          NaN   \n",
            "170                     NaN         NaN       X  NaN          NaN   \n",
            "171                     NaN         NaN       X  NaN          NaN   \n",
            "172                     NaN         NaN       X  NaN          NaN   \n",
            "173                     NaN         NaN       X  NaN          NaN   \n",
            "174                     NaN         NaN       X  NaN          NaN   \n",
            "1264                    NaN         NaN       X  NaN          NaN   \n",
            "1469                    NaN         NaN       X  NaN          NaN   \n",
            "1470                    NaN         NaN       X  NaN          NaN   \n",
            "1478                    NaN         NaN       X  NaN          NaN   \n",
            "1479                    NaN         NaN       X  NaN          NaN   \n",
            "1480                    NaN         NaN       X  NaN          NaN   \n",
            "1481                    NaN         NaN       X  NaN          NaN   \n",
            "1482                    NaN         NaN       X  NaN          NaN   \n",
            "1694                    NaN         NaN       X  NaN          NaN   \n",
            "1700                    NaN         NaN       X  NaN          NaN   \n",
            "1701                    NaN         NaN       X  NaN          NaN   \n",
            "1900              X     NaN         NaN          NaN          NaN   \n",
            "2033                    NaN         NaN       X  NaN          NaN   \n",
            "2034                    NaN         NaN       X  NaN          NaN   \n",
            "2035                    NaN         NaN       X  NaN          NaN   \n",
            "2036                    NaN         NaN       X  NaN          NaN   \n",
            "2037                    NaN         NaN       X  NaN          NaN   \n",
            "2045                    NaN         NaN       X  NaN          NaN   \n",
            "2046                    NaN         NaN       X  NaN          NaN   \n",
            "2047                    NaN         NaN       X  NaN          NaN   \n",
            "2049                    NaN         NaN       X  NaN          NaN   \n",
            "2050                    NaN         NaN       X  NaN          NaN   \n",
            "2051                    NaN         NaN       X  NaN          NaN   \n",
            "2052                    NaN         NaN       X  NaN          NaN   \n",
            "2053                    NaN         NaN       X  NaN          NaN   \n",
            "2054                    NaN         NaN       X  NaN          NaN   \n",
            "2055                    NaN         NaN       X  NaN          NaN   \n",
            "2848                    NaN         NaN       X  NaN          NaN   \n",
            "3756                    NaN         NaN       X  NaN          NaN   \n",
            "3765              X     NaN         NaN       X  NaN          NaN   \n",
            "3773                    NaN         NaN       X  NaN          NaN   \n",
            "3774                    NaN         NaN       X  NaN          NaN   \n",
            "4527                    NaN         NaN       X  NaN          NaN   \n",
            "4528                    NaN         NaN       X  NaN          NaN   \n",
            "4529                    NaN         NaN       X  NaN          NaN   \n",
            "\n",
            "     Situation report Cleaned Customer info  \n",
            "5                 NaN                 GIRNE  \n",
            "122               NaN                 GİRNE  \n",
            "123               NaN                 GIRNE  \n",
            "124               NaN                 GIRNE  \n",
            "133               NaN                 GIRNE  \n",
            "147               NaN                 GIRNE  \n",
            "155               NaN                 GIRNE  \n",
            "156               NaN                 GIRNE  \n",
            "157               NaN                 GIRNE  \n",
            "158               NaN                 GIRNE  \n",
            "159               NaN                 GIRNE  \n",
            "162               NaN                 GİRNE  \n",
            "163               NaN                 GİRNE  \n",
            "164               NaN                 GİRNE  \n",
            "165               NaN                 GİRNE  \n",
            "166               NaN                 GİRNE  \n",
            "167               NaN                 GİRNE  \n",
            "168               NaN                 GIRNE  \n",
            "169               NaN                 GIRNE  \n",
            "170               NaN                 GIRNE  \n",
            "171               NaN                 GIRNE  \n",
            "172               NaN                 GIRNE  \n",
            "173               NaN                 GIRNE  \n",
            "174               NaN                 GIRNE  \n",
            "1264              NaN                 GIRNE  \n",
            "1469              NaN                 GIRNE  \n",
            "1470              NaN                 GIRNE  \n",
            "1478              NaN                 GIRNE  \n",
            "1479              NaN                 GIRNE  \n",
            "1480              NaN                 GIRNE  \n",
            "1481              NaN                 GIRNE  \n",
            "1482              NaN                 GIRNE  \n",
            "1694              NaN                 GIRNE  \n",
            "1700              NaN                 GIRNE  \n",
            "1701              NaN                 GIRNE  \n",
            "1900              NaN                 GIRNE  \n",
            "2033              NaN                 GIRNE  \n",
            "2034              NaN                 GIRNE  \n",
            "2035              NaN                 GIRNE  \n",
            "2036              NaN                 GIRNE  \n",
            "2037              NaN                 GIRNE  \n",
            "2045              NaN                 GIRNE  \n",
            "2046              NaN                 GIRNE  \n",
            "2047              NaN                 GIRNE  \n",
            "2049              NaN                 GIRNE  \n",
            "2050              NaN                 GIRNE  \n",
            "2051              NaN                 GIRNE  \n",
            "2052              NaN                 GIRNE  \n",
            "2053              NaN                 GIRNE  \n",
            "2054              NaN                 GIRNE  \n",
            "2055              NaN                 GIRNE  \n",
            "2848              NaN                 GIRNE  \n",
            "3756              NaN                 GIRNE  \n",
            "3765              NaN                 GIRNE  \n",
            "3773              NaN                 GIRNE  \n",
            "3774              NaN                 GIRNE  \n",
            "4527              NaN                 GIRNE  \n",
            "4528              NaN                 GIRNE  \n",
            "4529              NaN                 GIRNE  \n",
            "\n",
            "[59 rows x 63 columns]\n",
            "Merged data has been saved to /content/cgniv_StarOrderplus_Order_items.xlsx\n",
            "Number of rows in the original df2 file: 3147\n",
            "Number of rows in the result file: 3147\n",
            "Updated file saved to /content/vaugzcstcketrd_expstckentryd_status_trcklnk_trckno.xlsx\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('BYE', [b'LOGOUT Requested'])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**İnclusion of mercedes yedek parca file 2025  for correlation  06/01/2025**"
      ],
      "metadata": {
        "id": "KPOmnchdq98U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from datetime import timedelta\n",
        "import imaplib\n",
        "import email\n",
        "from email.header import decode_header\n",
        "import chardet\n",
        "import re\n",
        "\n",
        "# Email account credentials\n",
        "username = 'kombosawb@gmail.com'\n",
        "password = 'kyka ypey hfar rjvg'  # Use the App Password here\n",
        "\n",
        "# File paths for input Excel files\n",
        "file_path = '/content/updated_Order_items (36).xlsx'\n",
        "file_path1 = '/content/updated_Mercedes_Yedek_Parça_Sipariş_2024 (36).xlsx'\n",
        "file_path2 = '/content/niv_StarOrderplus_Order_items_new.xlsx'\n",
        "file_path2025 = '/content/updated_Mercedes_Yedek_Parça_Sipariş_2025.xlsx'\n",
        "input_file = '/content/cgniv_StarOrderplus_Order_items.xlsx'\n",
        "\n",
        "# File path for the output Excel file\n",
        "output_file = '/content/vaugzcstcketrd_expstckentryd_status_trcklnk_trckno.xlsx'\n",
        "exdf1 = '/content/df1_unique.xlsx'\n",
        "exdf2 = '/content/df2.xlsx'\n",
        "\n",
        "# Load and clean the first Excel file\n",
        "df = pd.read_excel(file_path)\n",
        "\n",
        "# Create 'Cleaned Customer info' column by removing spaces, unwanted characters, and suffixes like '-i', '/G', etc.\n",
        "if 'Customer info' in df.columns:\n",
        "    # Updated regex to handle various suffixes including special characters\n",
        "    df['Cleaned Customer info'] = df['Customer info'].astype(str).str.replace(' ', '').str.upper().str.replace(r'[-/][A-ZİÝIi]+$', '', regex=True)\n",
        "else:\n",
        "    print(\"The column 'Customer info' was not found in the file.\")\n",
        "    df['Cleaned Customer info'] = df['Customer info']\n",
        "\n",
        "# Remove rows with unwanted 'Customer info' entries\n",
        "df_cleaned = df[~df['Cleaned Customer info'].str.lower().str.startswith(('stok', 'stpk', 'minarelikoy', 'mýna', 'stock', 'raf')) &\n",
        "                ~df['Cleaned Customer info'].str.startswith(('RAF', 'STOCKMT'))]\n",
        "\n",
        "# Save the cleaned DataFrame to a new Excel file\n",
        "df_cleaned.to_excel(file_path2, index=False)\n",
        "\n",
        "# Load the cleaned DataFrame and other Excel files\n",
        "df_cleaned = pd.read_excel(file_path2)\n",
        "df1_2024 = pd.read_excel(file_path1)\n",
        "df1_2025 = pd.read_excel(file_path2025)\n",
        "df2 = pd.read_excel(file_path2)\n",
        "\n",
        "# Combine 2024 and 2025 files for lookup\n",
        "df1_combined = pd.concat([df1_2024, df1_2025], ignore_index=True)\n",
        "\n",
        "# Check for required columns in df1_combined and df2\n",
        "required_columns = {'Customer info', 'Part number'}\n",
        "missing_columns_df1 = required_columns - set(df1_combined.columns)\n",
        "missing_columns_df2 = required_columns - set(df2.columns)\n",
        "\n",
        "if missing_columns_df1:\n",
        "    print(f\"The following required columns are missing in the combined file: {missing_columns_df1}\")\n",
        "if missing_columns_df2:\n",
        "    print(f\"The following required columns are missing in the second file: {missing_columns_df2}\")\n",
        "\n",
        "if not missing_columns_df1 and not missing_columns_df2:\n",
        "    # Clean 'Part number' columns in df1_combined and df2\n",
        "    df1_combined['Cleaned Part number'] = df1_combined['Part number'].astype(str).str.replace(' ', '').str.upper().str[:10]\n",
        "    df2['Cleaned Part number'] = df2['Part number'].astype(str).str.replace(' ', '').str.upper().str[:10]\n",
        "\n",
        "    # Clean 'Customer info' columns in df1_combined\n",
        "    df1_combined['Cleaned Customer info'] = df1_combined['Customer info'].astype(str).str.replace(' ', '').str.upper().str.replace(r'[-/][A-ZİÝIi]+$', '', regex=True)\n",
        "    df1_unique = df1_combined.drop_duplicates(subset=['Cleaned Customer info', 'Cleaned Part number'])\n",
        "\n",
        "    # Save df1_unique for verification\n",
        "    df1_unique.to_excel(exdf1, index=False)\n",
        "\n",
        "    # Clean 'Customer info' columns in df2\n",
        "    df2['Cleaned Customer info'] = df2['Customer info'].astype(str).str.replace(' ', '').str.upper().str.replace(r'[-/][A-ZİÝIi]+$', '', regex=True)\n",
        "\n",
        "    # Merge 'StockEntryDate' from df1_unique into df2 based on cleaned columns\n",
        "    merged_df = pd.merge(df2, df1_unique[['Cleaned Customer info', 'Cleaned Part number', 'StockEntryDate']],\n",
        "                         on=['Cleaned Customer info', 'Cleaned Part number'], how='left')\n",
        "\n",
        "    # Save the resulting DataFrame\n",
        "    merged_df.to_excel(input_file, index=False)\n",
        "    print(f\"Merged data has been saved to {input_file}\")\n",
        "    print(f\"Number of rows in the original df2 file: {len(df2)}\")\n",
        "    print(f\"Number of rows in the result file: {len(merged_df)}\")\n",
        "\n",
        "else:\n",
        "    print(\"One or both required columns 'Customer info' or 'Part number' were not found in the provided files.\")\n",
        "\n",
        "# Load the updated DataFrame\n",
        "df = pd.read_excel(input_file)\n",
        "\n",
        "# Define the function to compute the expected stock entry date\n",
        "def calculate_expected_stock_entry_date(row):\n",
        "    try:\n",
        "        inv_date_dispatch_date = pd.to_datetime(row['Inv. date dispatch date'], dayfirst=True, errors='coerce')\n",
        "        if pd.notnull(inv_date_dispatch_date):\n",
        "            conf_dd_confirmed_dispatch_date = pd.to_datetime(row['Conf. DD confirmed dispatch date'], dayfirst=True, errors='coerce')\n",
        "            expected_dd_expected_to_be_dispatched = pd.to_datetime(row['Expected DD expecte to be dispatched'], dayfirst=True, errors='coerce')\n",
        "\n",
        "            if row['Dist. ch.'] == 'af VOR direct':\n",
        "                days_to_add = 10\n",
        "            elif row['Dist. ch.'] == 'VOR route':\n",
        "                days_to_add = 21\n",
        "            else:\n",
        "                days_to_add = 10\n",
        "\n",
        "            return inv_date_dispatch_date + timedelta(days=days_to_add)\n",
        "        return pd.NaT\n",
        "    except KeyError as e:\n",
        "        print(f\"Column not found: {e}\")\n",
        "        return pd.NaT\n",
        "\n",
        "# Apply the function to each row to create the new column\n",
        "df['expectedstockentrydate'] = df.apply(calculate_expected_stock_entry_date, axis=1)\n",
        "\n",
        "# Define the function to compute the status\n",
        "def determine_status(row):\n",
        "    inv_date_dispatch_date = pd.to_datetime(row.get('Inv. date dispatch date', None), dayfirst=True, errors='coerce')\n",
        "    conf_dd_confirmed_dispatch_date = pd.to_datetime(row.get('Conf. DD confirmed dispatch date', None), dayfirst=True, errors='coerce')\n",
        "    expected_dd_expected_to_be_dispatched = pd.to_datetime(row.get('Expected DD expecte to be dispatched', None), dayfirst=True, errors='coerce')\n",
        "\n",
        "    if pd.notnull(inv_date_dispatch_date):\n",
        "        return f'invoice dispatch date on {inv_date_dispatch_date.strftime(\"%d/%m/%Y\")}'\n",
        "    elif pd.notnull(conf_dd_confirmed_dispatch_date):\n",
        "        return f'confirmed dispatch date on {conf_dd_confirmed_dispatch_date.strftime(\"%d/%m/%Y\")}'\n",
        "    elif pd.notnull(expected_dd_expected_to_be_dispatched):\n",
        "        return 'backorder'\n",
        "    else:\n",
        "        return 'backorder'\n",
        "\n",
        "# Apply the function to create the new status column\n",
        "df['status'] = df.apply(determine_status, axis=1)\n",
        "\n",
        "# Update status for rejected items\n",
        "df.loc[(df['Items status'] == 'Rejected') & (df['status'] == 'backorder'), 'status'] = 'Rejected'\n",
        "\n",
        "# Set StockEntryDate to NaT where status is 'backorder' or 'Rejected'\n",
        "df.loc[df['status'].isin(['backorder', 'Rejected']), 'StockEntryDate'] = pd.NaT\n",
        "\n",
        "# Save results to a new Excel file\n",
        "df.to_excel(output_file, index=False)\n",
        "print(f\"Updated file saved to {output_file}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "FVRjdsk3qkEB",
        "outputId": "2b340427-d337-4726-9a74-054cb2f424b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/updated_Mercedes_Yedek_Parça_Sipariş_2025.xlsx'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-9f2ebd2a3220>\u001b[0m in \u001b[0;36m<cell line: 46>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0mdf_cleaned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0mdf1_2024\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m \u001b[0mdf1_2025\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path2025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0mdf2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[0m\n\u001b[1;32m    493\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[0mshould_close\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 495\u001b[0;31m         io = ExcelFile(\n\u001b[0m\u001b[1;32m    496\u001b[0m             \u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[1;32m   1548\u001b[0m                 \u001b[0mext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xls\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1549\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1550\u001b[0;31m                 ext = inspect_excel_format(\n\u001b[0m\u001b[1;32m   1551\u001b[0m                     \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36minspect_excel_format\u001b[0;34m(content_or_path, storage_options)\u001b[0m\n\u001b[1;32m   1400\u001b[0m         \u001b[0mcontent_or_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent_or_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1402\u001b[0;31m     with get_handle(\n\u001b[0m\u001b[1;32m   1403\u001b[0m         \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1404\u001b[0m     ) as handle:\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    880\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 882\u001b[0;31m             \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    883\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/updated_Mercedes_Yedek_Parça_Sipariş_2025.xlsx'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**19122024 trial( it works, but use the one above )**"
      ],
      "metadata": {
        "id": "rAZ1vxVS367y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from datetime import timedelta\n",
        "import imaplib\n",
        "import email\n",
        "from email.header import decode_header\n",
        "import chardet\n",
        "import re\n",
        "\n",
        "# Email account credentials\n",
        "username = 'kombosawb@gmail.com'\n",
        "password = 'kyka ypey hfar rjvg'  # Use the App Password here\n",
        "\n",
        "# File paths for input Excel files\n",
        "file_path = '/content/updated_Order_items (34).xlsx'\n",
        "file_path1 = '/content/updated_Mercedes_Yedek_Parça_Sipariş_2024 (34).xlsx'\n",
        "file_path2 = '/content/niv_StarOrderplus_Order_items_new.xlsx'\n",
        "\n",
        "# File path for the output Excel file\n",
        "output_file = '/content/vaugzcstcketrd_expstckentryd_status_trcklnk_trckno.xlsx'\n",
        "\n",
        "# Load and clean the first Excel file\n",
        "df = pd.read_excel(file_path)\n",
        "\n",
        "# Create 'Cleaned Customer info' column by removing spaces, unwanted characters, and suffixes like '-i', '/G', etc.\n",
        "df['Cleaned Customer info'] = df['Customer info'].astype(str).str.replace(' ', '').str.upper().str.replace(r'[-/][A-ZİÝIi]+$', '', regex=True)\n",
        "\n",
        "# Remove rows with unwanted 'Customer info' entries\n",
        "df_cleaned = df[~df['Cleaned Customer info'].str.lower().str.startswith(('stok', 'stpk', 'minarelikoy', 'mýna', 'stock', 'raf')) &\n",
        "                ~df['Cleaned Customer info'].str.startswith(('RAF', 'STOCKMT'))]\n",
        "\n",
        "# Save the cleaned DataFrame to a new Excel file\n",
        "df_cleaned.to_excel(file_path2, index=False)\n",
        "\n",
        "# Load the cleaned DataFrame and other Excel files\n",
        "df_cleaned = pd.read_excel(file_path2)\n",
        "df1 = pd.read_excel(file_path1)\n",
        "df2 = pd.read_excel(file_path2)\n",
        "\n",
        "# Clean 'Part number' columns in df1 and df2\n",
        "df1['Cleaned Part number'] = df1['Part number'].astype(str).str.replace(' ', '').str.upper().str[:10]\n",
        "df2['Cleaned Part number'] = df2['Part number'].astype(str).str.replace(' ', '').str.upper().str[:10]\n",
        "\n",
        "# Clean 'Customer info' columns in df1\n",
        "df1['Cleaned Customer info'] = df1['Customer info'].astype(str).str.replace(' ', '').str.upper().str.replace(r'[-/][A-ZİÝIi]+$', '', regex=True)\n",
        "\n",
        "# Handle missing StockEntryDate by propagating the value from duplicates\n",
        "def fill_missing_stockentrydate(group):\n",
        "    \"\"\"\n",
        "    Fill missing StockEntryDate for duplicate rows within the same group.\n",
        "    If one row in the group has a StockEntryDate, propagate it to others.\n",
        "    \"\"\"\n",
        "    if group['StockEntryDate'].notna().any():\n",
        "        group['StockEntryDate'] = group['StockEntryDate'].fillna(method='bfill').fillna(method='ffill')\n",
        "    return group\n",
        "\n",
        "# Apply the function to fill missing StockEntryDates in Mercedes Yedek Parça file\n",
        "df1 = df1.groupby(['Cleaned Customer info', 'Cleaned Part number'], group_keys=False).apply(fill_missing_stockentrydate)\n",
        "\n",
        "# Merge 'StockEntryDate' from Mercedes Yedek Parça into Star Order file\n",
        "merged_df = pd.merge(\n",
        "    df2,\n",
        "    df1[['Cleaned Customer info', 'Cleaned Part number', 'StockEntryDate']],\n",
        "    on=['Cleaned Customer info', 'Cleaned Part number'],\n",
        "    how='left'\n",
        ")\n",
        "\n",
        "# Save the resulting DataFrame\n",
        "merged_df.to_excel(file_path2, index=False)\n",
        "\n",
        "# Define the function to compute the expected stock entry date\n",
        "def calculate_expected_stock_entry_date(row):\n",
        "    try:\n",
        "        inv_date_dispatch_date = pd.to_datetime(row['Inv. date dispatch date'], dayfirst=True, errors='coerce')\n",
        "        if pd.notnull(inv_date_dispatch_date):\n",
        "            days_to_add = 10 if row['Dist. ch.'] in ['af VOR direct', 'VOR route'] else 21\n",
        "            return inv_date_dispatch_date + timedelta(days=days_to_add)\n",
        "        return pd.NaT\n",
        "    except KeyError as e:\n",
        "        print(f\"Column not found: {e}\")\n",
        "        return pd.NaT\n",
        "\n",
        "# Apply the function to each row to create the new column\n",
        "merged_df['expectedstockentrydate'] = merged_df.apply(calculate_expected_stock_entry_date, axis=1)\n",
        "\n",
        "# Define the function to compute the status\n",
        "def determine_status(row):\n",
        "    inv_date_dispatch_date = pd.to_datetime(row.get('Inv. date dispatch date', None), dayfirst=True, errors='coerce')\n",
        "    conf_dd_confirmed_dispatch_date = pd.to_datetime(row.get('Conf. DD confirmed dispatch date', None), dayfirst=True, errors='coerce')\n",
        "    expected_dd_expected_to_be_dispatched = pd.to_datetime(row.get('Expected DD expecte to be dispatched', None), dayfirst=True, errors='coerce')\n",
        "\n",
        "    if pd.notnull(inv_date_dispatch_date):\n",
        "        return f'invoice dispatch date on {inv_date_dispatch_date.strftime(\"%d/%m/%Y\")}'\n",
        "    elif pd.notnull(conf_dd_confirmed_dispatch_date):\n",
        "        return f'confirmed dispatch date on {conf_dd_confirmed_dispatch_date.strftime(\"%d/%m/%Y\")}'\n",
        "    elif pd.notnull(expected_dd_expected_to_be_dispatched):\n",
        "        return 'backorder'\n",
        "    else:\n",
        "        return 'backorder'\n",
        "\n",
        "# Apply the function to create the new status column\n",
        "merged_df['status'] = merged_df.apply(determine_status, axis=1)\n",
        "\n",
        "# Update status for rejected items\n",
        "merged_df.loc[(merged_df['Items status'] == 'Rejected') & (merged_df['status'] == 'backorder'), 'status'] = 'Rejected'\n",
        "\n",
        "# Filter out 'Rejected' items when searching for backorders\n",
        "filtered_df = merged_df[(merged_df['status'] == 'backorder')]\n",
        "\n",
        "# Fetch tracking numbers from emails\n",
        "def fetch_stt_number(body):\n",
        "    stt_number_match = re.search(r'STT Number[:\\.\\s]+(\\d+)', body)\n",
        "    return stt_number_match.group(1) if stt_number_match else 'Not Found'\n",
        "\n",
        "def search_emails_for_tracking_numbers(dn_numbers):\n",
        "    tracking_dict = {dn_number: 'Not Found' for dn_number in dn_numbers}\n",
        "    mail = imaplib.IMAP4_SSL('imap.gmail.com')\n",
        "    mail.login(username, password)\n",
        "    mail.select('inbox')\n",
        "\n",
        "    result, data = mail.search(None, 'ALL')\n",
        "    if result != 'OK':\n",
        "        print(\"Failed to search for emails.\")\n",
        "        return tracking_dict\n",
        "\n",
        "    email_ids = data[0].split()\n",
        "    for email_id in email_ids:\n",
        "        result, msg_data = mail.fetch(email_id, '(RFC822)')\n",
        "        if result != 'OK':\n",
        "            continue\n",
        "\n",
        "        raw_email = msg_data[0][1]\n",
        "        msg = email.message_from_bytes(raw_email)\n",
        "\n",
        "        body = \"\"\n",
        "        if msg.is_multipart():\n",
        "            for part in msg.walk():\n",
        "                if part.get_content_type() == 'text/plain':\n",
        "                    payload = part.get_payload(decode=True)\n",
        "                    detected_encoding = chardet.detect(payload)['encoding']\n",
        "                    body = payload.decode(detected_encoding or 'utf-8', errors='replace')\n",
        "                    break\n",
        "        else:\n",
        "            payload = msg.get_payload(decode=True)\n",
        "            detected_encoding = chardet.detect(payload)['encoding']\n",
        "            body = payload.decode(detected_encoding or 'utf-8', errors='replace')\n",
        "\n",
        "        for dn_number in dn_numbers:\n",
        "            if dn_number in body:\n",
        "                tracking_dict[dn_number] = fetch_stt_number(body)\n",
        "\n",
        "    mail.close()\n",
        "    mail.logout()\n",
        "    return tracking_dict\n",
        "\n",
        "dn_numbers = merged_df['DN no.'].dropna().astype(str).tolist()\n",
        "tracking_dict = search_emails_for_tracking_numbers(dn_numbers)\n",
        "\n",
        "# Update with tracking numbers and links\n",
        "merged_df['Tracking No'] = merged_df['DN no.'].map(tracking_dict)\n",
        "merged_df['tracking_details'] = merged_df['Tracking No'].apply(\n",
        "    lambda x: f'https://dbschenker.com/app/tracking-public/?refNumber={x}' if x != 'Not Found' else ''\n",
        ")\n",
        "\n",
        "# Save the final output\n",
        "merged_df.to_excel(output_file, index=False)\n",
        "print(f\"Final updated file saved to {output_file}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wxozz3MZZF4o",
        "outputId": "fb2b75c5-c949-43bc-f315-5c811097d854"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-613ec88e546f>:53: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  group['StockEntryDate'] = group['StockEntryDate'].fillna(method='bfill').fillna(method='ffill')\n",
            "<ipython-input-3-613ec88e546f>:53: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  group['StockEntryDate'] = group['StockEntryDate'].fillna(method='bfill').fillna(method='ffill')\n",
            "<ipython-input-3-613ec88e546f>:57: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  df1 = df1.groupby(['Cleaned Customer info', 'Cleaned Part number'], group_keys=False).apply(fill_missing_stockentrydate)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final updated file saved to /content/vaugzcstcketrd_expstckentryd_status_trcklnk_trckno.xlsx\n"
          ]
        }
      ]
    }
  ]
}